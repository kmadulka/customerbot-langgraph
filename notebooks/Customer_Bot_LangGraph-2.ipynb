{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0adaf0e-c328-44d1-a49c-2731a90b94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43bf9266-20c2-417a-8c01-a5d95d97c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from typing import Dict, List, Optional, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, trim_messages, BaseMessage\n",
    "\n",
    "\n",
    "from typing import Sequence, Literal\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import pandas as pd\n",
    "import random\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# from langchain.chains import StateGraph\n",
    "# from langchain.memory import MemorySaver\n",
    "import random\n",
    "import json\n",
    "\n",
    "os.environ[\"MERMAID_TIMEOUT\"] = \"30\"\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4efe9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              call_id  \\\n",
      "0  WR1bd667dd7bb992e7928181aee12cab13   \n",
      "1  WR0d53a33c1b0614b7788d5bdee1be6957   \n",
      "2  WR1555c9e2af4a8fe0158173f8bd1bc745   \n",
      "3  WR138d5a96a25b79fbc7589bc71b7aa181   \n",
      "4  WR08d7a0ce50ff11700972b1c4ac3f6493   \n",
      "5  WR0c17f7ec94ebdb9ce4fb0cc3fe60a226   \n",
      "6  WR113bde969c4cf499124479563d53a7d4   \n",
      "7  WR0528c0e914fb6f7d33db59793bcd421f   \n",
      "8  WR14808051796fe2b4be5e5ac9413e126b   \n",
      "\n",
      "                                  agent_strategy_bad  \\\n",
      "0  The agent could have been clearer in explainin...   \n",
      "1  The agent could improve by quickly identifying...   \n",
      "2  The agent could have provided more information...   \n",
      "3  The agent did not directly address the custome...   \n",
      "4  The agent repeatedly called the customer by th...   \n",
      "5  The agent could have better addressed the cust...   \n",
      "6  The agent was unable to correct the customer's...   \n",
      "7  The agent could improve by proactively address...   \n",
      "8  The agent continues to pitch services unrelate...   \n",
      "\n",
      "                                 agent_strategy_good  \\\n",
      "0  The agent was persistent in trying to find a s...   \n",
      "1  The agent clearly explains the purpose of the ...   \n",
      "2  The agent clarified the ownership of Xfinity, ...   \n",
      "3  The agent collected all necessary personal inf...   \n",
      "4  The agent provided detailed information about ...   \n",
      "5  The agent maintained a polite and patient deme...   \n",
      "6  The agent was patient and checked multiple tim...   \n",
      "7  The agent was polite and patient, providing cl...   \n",
      "8  The agent attempts to confirm details and offe...   \n",
      "\n",
      "                          communication_style_pacing  \\\n",
      "0  The customer responds promptly with short answ...   \n",
      "1  The customer takes time to process information...   \n",
      "2  Responses are quick and to the point, asking d...   \n",
      "3  The customer provides information promptly and...   \n",
      "4  Quick to respond, wants concise and direct inf...   \n",
      "5  The customer responds quickly and is generally...   \n",
      "6  The customer responds quickly and concisely. T...   \n",
      "7  Quick to respond, asks questions for clarifica...   \n",
      "8  Quick to express dissatisfaction and focus on ...   \n",
      "\n",
      "                      communication_style_politeness  \\\n",
      "0                                             Polite   \n",
      "1                                             polite   \n",
      "2                Polite, direct and straightforward.   \n",
      "3                                             polite   \n",
      "4                                             Abrupt   \n",
      "5                                             polite   \n",
      "6                                             polite   \n",
      "7                                             Polite   \n",
      "8  Polite but assertive about dissatisfaction wit...   \n",
      "\n",
      "                                            concerns  \\\n",
      "0  The customer expressed concern about not havin...   \n",
      "1  The customer is concerned with healthcare insu...   \n",
      "2  The customer is concerned about channel availa...   \n",
      "3  The customer is primarily concerned with findi...   \n",
      "4  Concerned about internet speed, pricing, and t...   \n",
      "5  The customer expressed concerns about the pric...   \n",
      "6  The customer is concerned about the availabili...   \n",
      "7  Customer wanted the internet setup sooner, pre...   \n",
      "8  Customer is frustrated with Spectrum's billing...   \n",
      "\n",
      "                          customer_beginning_of_call  \\\n",
      "0  The customer initially seems a bit unclear in ...   \n",
      "1  The customer responds with a simple 'Good' whe...   \n",
      "2  The customer introduces himself as Steve Stoop...   \n",
      "3  The customer began the call by stating their i...   \n",
      "4  The customer is upset and wants to get the con...   \n",
      "5  The customer, Anthony, begins the call by intr...   \n",
      "6  The customer responds promptly and politely wi...   \n",
      "7  Margaret is straightforward and polite at the ...   \n",
      "8  Renee begins the call by expressing irritation...   \n",
      "\n",
      "                                customer_information  \\\n",
      "0  Name: Steph Curry, Email: scott.shanetta@yahoo...   \n",
      "1                                Name: Kenny Landing   \n",
      "2  Name: Steve Stoop, Email: stevestoopahoo.com, ...   \n",
      "3  Name: Clayton Blue, Email: Claytonblue617@gmai...   \n",
      "4  Name: Jeremiah Donald; Email: thesilverfox@gma...   \n",
      "5  Name: Anthony Baker, Phone: 543-642-8958, Emai...   \n",
      "6                                  Name: Craig Smith   \n",
      "7  Name: Madison Orange, Email: awengr9@gmail.com...   \n",
      "8  Name: Renee Valentine, Address: 11063 East Mou...   \n",
      "\n",
      "                        customer_off_track_responses  \\\n",
      "0                       The customer stays on track.   \n",
      "1  The customer repeatedly talks about healthcare...   \n",
      "2  The customer goes off track discussing the Dis...   \n",
      "3                            customer stays on track   \n",
      "4  Customer mostly stays on track but expresses f...   \n",
      "5  The customer takes the conversation off-track ...   \n",
      "6  The customer stays on track, focusing primaril...   \n",
      "7  Customer stays mostly on track, briefly mentio...   \n",
      "8  Customer stays on track talking about internet...   \n",
      "\n",
      "                                   emotional_moments  ...  \\\n",
      "0  There was a moment of concern when the custome...  ...   \n",
      "1  The customer shows confusion about the purpose...  ...   \n",
      "2  Expressed mild frustration over price increase...  ...   \n",
      "3         None notable from the provided transcript.  ...   \n",
      "4  Frustration when mistaken for a woman and irri...  ...   \n",
      "5  The customer was slightly amused and curious a...  ...   \n",
      "6  There was some frustration when the customer r...  ...   \n",
      "7  Expressed mild frustration and disappointment ...  ...   \n",
      "8  Expresses frustration over Spectrum's billing ...  ...   \n",
      "\n",
      "                           products_pitched_question  \\\n",
      "0  Inquired about the due payment; showed interes...   \n",
      "1                                                NaN   \n",
      "2  How much would it cost per month? Would I be a...   \n",
      "3  The customer asked about the cheapest internet...   \n",
      "4                          How fast is the internet?   \n",
      "5  Asked about pricing, speed, contract terms, an...   \n",
      "6  They questioned the provider, Earthlink, and t...   \n",
      "7  Asked about the possibility of picking up equi...   \n",
      "8                             Do they have internet?   \n",
      "\n",
      "                           products_pitched_reaction  \\\n",
      "0  The customer expressed inability to pay the up...   \n",
      "1                                                NaN   \n",
      "2  Curious but non-committal. The customer wants ...   \n",
      "3  The customer repeatedly emphasizes their inter...   \n",
      "4  Customer found it too low and asked for the ne...   \n",
      "5  Initially skeptical about the affordability of...   \n",
      "6  The customer was skeptical about the price, ex...   \n",
      "7  Initially accepting but concerned about the wa...   \n",
      "8  Customer is not interested as they only need i...   \n",
      "\n",
      "  products_pitched_sentoment sentiment  \\\n",
      "0                    neutral   neutral   \n",
      "1                        NaN   neutral   \n",
      "2                    neutral   neutral   \n",
      "3                    neutral   neutral   \n",
      "4                   negative   neutral   \n",
      "5                    neutral   neutral   \n",
      "6                   negative   neutral   \n",
      "7                    neutral   neutral   \n",
      "8                   negative  negative   \n",
      "\n",
      "                                     summary_of_call        tone  \\\n",
      "0  The call involved the agent attempting to pitc...     neutral   \n",
      "1  The customer, Kenny Landing, mistakenly called...     neutral   \n",
      "2  Steve Stoop called to inquire about TV service...     neutral   \n",
      "3  Clayton Blue called AllConnect to inquire abou...     neutral   \n",
      "4  The customer, Jeremiah Donald, expressed frust...  frustrated   \n",
      "5  Anthony contacted AllConnect to explore intern...     neutral   \n",
      "6  Craig Smith called to inquire about internet s...     neutral   \n",
      "7  Madison Orange called to set up internet servi...     neutral   \n",
      "8  Renee Valentine is frustrated with Spectrum du...  Frustrated   \n",
      "\n",
      "  device_count_captured transfer_type_captured provider_captured  \\\n",
      "0                     6                    new           unknown   \n",
      "1                     0               transfer               NaN   \n",
      "2                     2                    new           DIRECTV   \n",
      "3                     3                    new           Xfinity   \n",
      "4                     5                    new           unknown   \n",
      "5                     7                    new           unknown   \n",
      "6                     3                    new           unknown   \n",
      "7                     1                    new           unknown   \n",
      "8                     3                    new          Spectrum   \n",
      "\n",
      "                         usage_captured  \n",
      "0        working_from_home,heavy_gaming  \n",
      "1                                   NaN  \n",
      "2                                   NaN  \n",
      "3                              browsing  \n",
      "4                          heavy_gaming  \n",
      "5                     working_from_home  \n",
      "6                     working_from_home  \n",
      "7  streaming,browsing,working_from_home  \n",
      "8                                   NaN  \n",
      "\n",
      "[9 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# test = pd.read_csv(\"./data/customer_profile_samp_modified.csv\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate up two levels (assuming your structure is 'repo-root/src/data')\n",
    "repo_root_directory = os.path.abspath(os.path.join(current_directory, '..'))\n",
    "\n",
    "# Construct the path to the data folder\n",
    "file_path = os.path.join(repo_root_directory, 'data', 'customer_profile_samp_modified.csv')\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print or use the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa918f80-528a-4116-abdc-ff0113d398cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_id</th>\n",
       "      <th>agent_strategy_bad</th>\n",
       "      <th>agent_strategy_good</th>\n",
       "      <th>communication_style_pacing</th>\n",
       "      <th>communication_style_politeness</th>\n",
       "      <th>concerns</th>\n",
       "      <th>customer_beginning_of_call</th>\n",
       "      <th>customer_information</th>\n",
       "      <th>customer_off_track_responses</th>\n",
       "      <th>emotional_moments</th>\n",
       "      <th>...</th>\n",
       "      <th>products_pitched_question</th>\n",
       "      <th>products_pitched_reaction</th>\n",
       "      <th>products_pitched_sentoment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary_of_call</th>\n",
       "      <th>tone</th>\n",
       "      <th>device_count_captured</th>\n",
       "      <th>transfer_type_captured</th>\n",
       "      <th>provider_captured</th>\n",
       "      <th>usage_captured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WR1bd667dd7bb992e7928181aee12cab13</td>\n",
       "      <td>The agent could have been clearer in explainin...</td>\n",
       "      <td>The agent was persistent in trying to find a s...</td>\n",
       "      <td>The customer responds promptly with short answ...</td>\n",
       "      <td>Polite</td>\n",
       "      <td>The customer expressed concern about not havin...</td>\n",
       "      <td>The customer initially seems a bit unclear in ...</td>\n",
       "      <td>Name: Steph Curry, Email: scott.shanetta@yahoo...</td>\n",
       "      <td>The customer stays on track.</td>\n",
       "      <td>There was a moment of concern when the custome...</td>\n",
       "      <td>...</td>\n",
       "      <td>Inquired about the due payment; showed interes...</td>\n",
       "      <td>The customer expressed inability to pay the up...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The call involved the agent attempting to pitc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>6</td>\n",
       "      <td>new</td>\n",
       "      <td>unknown</td>\n",
       "      <td>working_from_home,heavy_gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WR0d53a33c1b0614b7788d5bdee1be6957</td>\n",
       "      <td>The agent could improve by quickly identifying...</td>\n",
       "      <td>The agent clearly explains the purpose of the ...</td>\n",
       "      <td>The customer takes time to process information...</td>\n",
       "      <td>polite</td>\n",
       "      <td>The customer is concerned with healthcare insu...</td>\n",
       "      <td>The customer responds with a simple 'Good' whe...</td>\n",
       "      <td>Name: Kenny Landing</td>\n",
       "      <td>The customer repeatedly talks about healthcare...</td>\n",
       "      <td>The customer shows confusion about the purpose...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The customer, Kenny Landing, mistakenly called...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>transfer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WR1555c9e2af4a8fe0158173f8bd1bc745</td>\n",
       "      <td>The agent could have provided more information...</td>\n",
       "      <td>The agent clarified the ownership of Xfinity, ...</td>\n",
       "      <td>Responses are quick and to the point, asking d...</td>\n",
       "      <td>Polite, direct and straightforward.</td>\n",
       "      <td>The customer is concerned about channel availa...</td>\n",
       "      <td>The customer introduces himself as Steve Stoop...</td>\n",
       "      <td>Name: Steve Stoop, Email: stevestoopahoo.com, ...</td>\n",
       "      <td>The customer goes off track discussing the Dis...</td>\n",
       "      <td>Expressed mild frustration over price increase...</td>\n",
       "      <td>...</td>\n",
       "      <td>How much would it cost per month? Would I be a...</td>\n",
       "      <td>Curious but non-committal. The customer wants ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Steve Stoop called to inquire about TV service...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>new</td>\n",
       "      <td>DIRECTV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WR138d5a96a25b79fbc7589bc71b7aa181</td>\n",
       "      <td>The agent did not directly address the custome...</td>\n",
       "      <td>The agent collected all necessary personal inf...</td>\n",
       "      <td>The customer provides information promptly and...</td>\n",
       "      <td>polite</td>\n",
       "      <td>The customer is primarily concerned with findi...</td>\n",
       "      <td>The customer began the call by stating their i...</td>\n",
       "      <td>Name: Clayton Blue, Email: Claytonblue617@gmai...</td>\n",
       "      <td>customer stays on track</td>\n",
       "      <td>None notable from the provided transcript.</td>\n",
       "      <td>...</td>\n",
       "      <td>The customer asked about the cheapest internet...</td>\n",
       "      <td>The customer repeatedly emphasizes their inter...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Clayton Blue called AllConnect to inquire abou...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>new</td>\n",
       "      <td>Xfinity</td>\n",
       "      <td>browsing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WR08d7a0ce50ff11700972b1c4ac3f6493</td>\n",
       "      <td>The agent repeatedly called the customer by th...</td>\n",
       "      <td>The agent provided detailed information about ...</td>\n",
       "      <td>Quick to respond, wants concise and direct inf...</td>\n",
       "      <td>Abrupt</td>\n",
       "      <td>Concerned about internet speed, pricing, and t...</td>\n",
       "      <td>The customer is upset and wants to get the con...</td>\n",
       "      <td>Name: Jeremiah Donald; Email: thesilverfox@gma...</td>\n",
       "      <td>Customer mostly stays on track but expresses f...</td>\n",
       "      <td>Frustration when mistaken for a woman and irri...</td>\n",
       "      <td>...</td>\n",
       "      <td>How fast is the internet?</td>\n",
       "      <td>Customer found it too low and asked for the ne...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The customer, Jeremiah Donald, expressed frust...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>5</td>\n",
       "      <td>new</td>\n",
       "      <td>unknown</td>\n",
       "      <td>heavy_gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WR0c17f7ec94ebdb9ce4fb0cc3fe60a226</td>\n",
       "      <td>The agent could have better addressed the cust...</td>\n",
       "      <td>The agent maintained a polite and patient deme...</td>\n",
       "      <td>The customer responds quickly and is generally...</td>\n",
       "      <td>polite</td>\n",
       "      <td>The customer expressed concerns about the pric...</td>\n",
       "      <td>The customer, Anthony, begins the call by intr...</td>\n",
       "      <td>Name: Anthony Baker, Phone: 543-642-8958, Emai...</td>\n",
       "      <td>The customer takes the conversation off-track ...</td>\n",
       "      <td>The customer was slightly amused and curious a...</td>\n",
       "      <td>...</td>\n",
       "      <td>Asked about pricing, speed, contract terms, an...</td>\n",
       "      <td>Initially skeptical about the affordability of...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Anthony contacted AllConnect to explore intern...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>new</td>\n",
       "      <td>unknown</td>\n",
       "      <td>working_from_home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WR113bde969c4cf499124479563d53a7d4</td>\n",
       "      <td>The agent was unable to correct the customer's...</td>\n",
       "      <td>The agent was patient and checked multiple tim...</td>\n",
       "      <td>The customer responds quickly and concisely. T...</td>\n",
       "      <td>polite</td>\n",
       "      <td>The customer is concerned about the availabili...</td>\n",
       "      <td>The customer responds promptly and politely wi...</td>\n",
       "      <td>Name: Craig Smith</td>\n",
       "      <td>The customer stays on track, focusing primaril...</td>\n",
       "      <td>There was some frustration when the customer r...</td>\n",
       "      <td>...</td>\n",
       "      <td>They questioned the provider, Earthlink, and t...</td>\n",
       "      <td>The customer was skeptical about the price, ex...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Craig Smith called to inquire about internet s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>new</td>\n",
       "      <td>unknown</td>\n",
       "      <td>working_from_home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WR0528c0e914fb6f7d33db59793bcd421f</td>\n",
       "      <td>The agent could improve by proactively address...</td>\n",
       "      <td>The agent was polite and patient, providing cl...</td>\n",
       "      <td>Quick to respond, asks questions for clarifica...</td>\n",
       "      <td>Polite</td>\n",
       "      <td>Customer wanted the internet setup sooner, pre...</td>\n",
       "      <td>Margaret is straightforward and polite at the ...</td>\n",
       "      <td>Name: Madison Orange, Email: awengr9@gmail.com...</td>\n",
       "      <td>Customer stays mostly on track, briefly mentio...</td>\n",
       "      <td>Expressed mild frustration and disappointment ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Asked about the possibility of picking up equi...</td>\n",
       "      <td>Initially accepting but concerned about the wa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Madison Orange called to set up internet servi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>unknown</td>\n",
       "      <td>streaming,browsing,working_from_home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WR14808051796fe2b4be5e5ac9413e126b</td>\n",
       "      <td>The agent continues to pitch services unrelate...</td>\n",
       "      <td>The agent attempts to confirm details and offe...</td>\n",
       "      <td>Quick to express dissatisfaction and focus on ...</td>\n",
       "      <td>Polite but assertive about dissatisfaction wit...</td>\n",
       "      <td>Customer is frustrated with Spectrum's billing...</td>\n",
       "      <td>Renee begins the call by expressing irritation...</td>\n",
       "      <td>Name: Renee Valentine, Address: 11063 East Mou...</td>\n",
       "      <td>Customer stays on track talking about internet...</td>\n",
       "      <td>Expresses frustration over Spectrum's billing ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Do they have internet?</td>\n",
       "      <td>Customer is not interested as they only need i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Renee Valentine is frustrated with Spectrum du...</td>\n",
       "      <td>Frustrated</td>\n",
       "      <td>3</td>\n",
       "      <td>new</td>\n",
       "      <td>Spectrum</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              call_id  \\\n",
       "0  WR1bd667dd7bb992e7928181aee12cab13   \n",
       "1  WR0d53a33c1b0614b7788d5bdee1be6957   \n",
       "2  WR1555c9e2af4a8fe0158173f8bd1bc745   \n",
       "3  WR138d5a96a25b79fbc7589bc71b7aa181   \n",
       "4  WR08d7a0ce50ff11700972b1c4ac3f6493   \n",
       "5  WR0c17f7ec94ebdb9ce4fb0cc3fe60a226   \n",
       "6  WR113bde969c4cf499124479563d53a7d4   \n",
       "7  WR0528c0e914fb6f7d33db59793bcd421f   \n",
       "8  WR14808051796fe2b4be5e5ac9413e126b   \n",
       "\n",
       "                                  agent_strategy_bad  \\\n",
       "0  The agent could have been clearer in explainin...   \n",
       "1  The agent could improve by quickly identifying...   \n",
       "2  The agent could have provided more information...   \n",
       "3  The agent did not directly address the custome...   \n",
       "4  The agent repeatedly called the customer by th...   \n",
       "5  The agent could have better addressed the cust...   \n",
       "6  The agent was unable to correct the customer's...   \n",
       "7  The agent could improve by proactively address...   \n",
       "8  The agent continues to pitch services unrelate...   \n",
       "\n",
       "                                 agent_strategy_good  \\\n",
       "0  The agent was persistent in trying to find a s...   \n",
       "1  The agent clearly explains the purpose of the ...   \n",
       "2  The agent clarified the ownership of Xfinity, ...   \n",
       "3  The agent collected all necessary personal inf...   \n",
       "4  The agent provided detailed information about ...   \n",
       "5  The agent maintained a polite and patient deme...   \n",
       "6  The agent was patient and checked multiple tim...   \n",
       "7  The agent was polite and patient, providing cl...   \n",
       "8  The agent attempts to confirm details and offe...   \n",
       "\n",
       "                          communication_style_pacing  \\\n",
       "0  The customer responds promptly with short answ...   \n",
       "1  The customer takes time to process information...   \n",
       "2  Responses are quick and to the point, asking d...   \n",
       "3  The customer provides information promptly and...   \n",
       "4  Quick to respond, wants concise and direct inf...   \n",
       "5  The customer responds quickly and is generally...   \n",
       "6  The customer responds quickly and concisely. T...   \n",
       "7  Quick to respond, asks questions for clarifica...   \n",
       "8  Quick to express dissatisfaction and focus on ...   \n",
       "\n",
       "                      communication_style_politeness  \\\n",
       "0                                             Polite   \n",
       "1                                             polite   \n",
       "2                Polite, direct and straightforward.   \n",
       "3                                             polite   \n",
       "4                                             Abrupt   \n",
       "5                                             polite   \n",
       "6                                             polite   \n",
       "7                                             Polite   \n",
       "8  Polite but assertive about dissatisfaction wit...   \n",
       "\n",
       "                                            concerns  \\\n",
       "0  The customer expressed concern about not havin...   \n",
       "1  The customer is concerned with healthcare insu...   \n",
       "2  The customer is concerned about channel availa...   \n",
       "3  The customer is primarily concerned with findi...   \n",
       "4  Concerned about internet speed, pricing, and t...   \n",
       "5  The customer expressed concerns about the pric...   \n",
       "6  The customer is concerned about the availabili...   \n",
       "7  Customer wanted the internet setup sooner, pre...   \n",
       "8  Customer is frustrated with Spectrum's billing...   \n",
       "\n",
       "                          customer_beginning_of_call  \\\n",
       "0  The customer initially seems a bit unclear in ...   \n",
       "1  The customer responds with a simple 'Good' whe...   \n",
       "2  The customer introduces himself as Steve Stoop...   \n",
       "3  The customer began the call by stating their i...   \n",
       "4  The customer is upset and wants to get the con...   \n",
       "5  The customer, Anthony, begins the call by intr...   \n",
       "6  The customer responds promptly and politely wi...   \n",
       "7  Margaret is straightforward and polite at the ...   \n",
       "8  Renee begins the call by expressing irritation...   \n",
       "\n",
       "                                customer_information  \\\n",
       "0  Name: Steph Curry, Email: scott.shanetta@yahoo...   \n",
       "1                                Name: Kenny Landing   \n",
       "2  Name: Steve Stoop, Email: stevestoopahoo.com, ...   \n",
       "3  Name: Clayton Blue, Email: Claytonblue617@gmai...   \n",
       "4  Name: Jeremiah Donald; Email: thesilverfox@gma...   \n",
       "5  Name: Anthony Baker, Phone: 543-642-8958, Emai...   \n",
       "6                                  Name: Craig Smith   \n",
       "7  Name: Madison Orange, Email: awengr9@gmail.com...   \n",
       "8  Name: Renee Valentine, Address: 11063 East Mou...   \n",
       "\n",
       "                        customer_off_track_responses  \\\n",
       "0                       The customer stays on track.   \n",
       "1  The customer repeatedly talks about healthcare...   \n",
       "2  The customer goes off track discussing the Dis...   \n",
       "3                            customer stays on track   \n",
       "4  Customer mostly stays on track but expresses f...   \n",
       "5  The customer takes the conversation off-track ...   \n",
       "6  The customer stays on track, focusing primaril...   \n",
       "7  Customer stays mostly on track, briefly mentio...   \n",
       "8  Customer stays on track talking about internet...   \n",
       "\n",
       "                                   emotional_moments  ...  \\\n",
       "0  There was a moment of concern when the custome...  ...   \n",
       "1  The customer shows confusion about the purpose...  ...   \n",
       "2  Expressed mild frustration over price increase...  ...   \n",
       "3         None notable from the provided transcript.  ...   \n",
       "4  Frustration when mistaken for a woman and irri...  ...   \n",
       "5  The customer was slightly amused and curious a...  ...   \n",
       "6  There was some frustration when the customer r...  ...   \n",
       "7  Expressed mild frustration and disappointment ...  ...   \n",
       "8  Expresses frustration over Spectrum's billing ...  ...   \n",
       "\n",
       "                           products_pitched_question  \\\n",
       "0  Inquired about the due payment; showed interes...   \n",
       "1                                                NaN   \n",
       "2  How much would it cost per month? Would I be a...   \n",
       "3  The customer asked about the cheapest internet...   \n",
       "4                          How fast is the internet?   \n",
       "5  Asked about pricing, speed, contract terms, an...   \n",
       "6  They questioned the provider, Earthlink, and t...   \n",
       "7  Asked about the possibility of picking up equi...   \n",
       "8                             Do they have internet?   \n",
       "\n",
       "                           products_pitched_reaction  \\\n",
       "0  The customer expressed inability to pay the up...   \n",
       "1                                                NaN   \n",
       "2  Curious but non-committal. The customer wants ...   \n",
       "3  The customer repeatedly emphasizes their inter...   \n",
       "4  Customer found it too low and asked for the ne...   \n",
       "5  Initially skeptical about the affordability of...   \n",
       "6  The customer was skeptical about the price, ex...   \n",
       "7  Initially accepting but concerned about the wa...   \n",
       "8  Customer is not interested as they only need i...   \n",
       "\n",
       "  products_pitched_sentoment sentiment  \\\n",
       "0                    neutral   neutral   \n",
       "1                        NaN   neutral   \n",
       "2                    neutral   neutral   \n",
       "3                    neutral   neutral   \n",
       "4                   negative   neutral   \n",
       "5                    neutral   neutral   \n",
       "6                   negative   neutral   \n",
       "7                    neutral   neutral   \n",
       "8                   negative  negative   \n",
       "\n",
       "                                     summary_of_call        tone  \\\n",
       "0  The call involved the agent attempting to pitc...     neutral   \n",
       "1  The customer, Kenny Landing, mistakenly called...     neutral   \n",
       "2  Steve Stoop called to inquire about TV service...     neutral   \n",
       "3  Clayton Blue called AllConnect to inquire abou...     neutral   \n",
       "4  The customer, Jeremiah Donald, expressed frust...  frustrated   \n",
       "5  Anthony contacted AllConnect to explore intern...     neutral   \n",
       "6  Craig Smith called to inquire about internet s...     neutral   \n",
       "7  Madison Orange called to set up internet servi...     neutral   \n",
       "8  Renee Valentine is frustrated with Spectrum du...  Frustrated   \n",
       "\n",
       "  device_count_captured transfer_type_captured provider_captured  \\\n",
       "0                     6                    new           unknown   \n",
       "1                     0               transfer               NaN   \n",
       "2                     2                    new           DIRECTV   \n",
       "3                     3                    new           Xfinity   \n",
       "4                     5                    new           unknown   \n",
       "5                     7                    new           unknown   \n",
       "6                     3                    new           unknown   \n",
       "7                     1                    new           unknown   \n",
       "8                     3                    new          Spectrum   \n",
       "\n",
       "                         usage_captured  \n",
       "0        working_from_home,heavy_gaming  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                              browsing  \n",
       "4                          heavy_gaming  \n",
       "5                     working_from_home  \n",
       "6                     working_from_home  \n",
       "7  streaming,browsing,working_from_home  \n",
       "8                                   NaN  \n",
       "\n",
       "[9 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_profile_df = pd.read_csv('/Users/kassandramadulka/Documents/github/customerbot-langgraph/data/customer_profile_samp_modified.csv')\n",
    "customer_profile_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5b995af-bbe3-4840-918e-a828c05907cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "# class DecisionOutput(str, Enum):\n",
    "#     \"\"\"The actions the emotions can decide to take\n",
    "#     \"\"\"\n",
    "#     ASK_QUESTION = \"ask_question\"\n",
    "#     HESITATE_TO_BUY = \"hesitate_to_buy\"\n",
    "#     TAKE_CONVERSATION_OFF_TRACK = \"take_conversation_off_track\"\n",
    "#     GET_FRUSTRATED = \"get_frustrated\"\n",
    "#     OBJECTION = \"objection\"\n",
    "#     INTERESTED_IN_BUYING = \"interested_in_buying\"\n",
    "#     ANSWER_AGENT_QUESTION = \"answer_agent_question\"\n",
    "#     CONTINUE_CONVERSATION = \"continue_conversation\"\n",
    "\n",
    "class EmotionalAnalysis(BaseModel):\n",
    "    emotions: Dict[str, float] = Field(\n",
    "        ..., default_factory=dict, description=\"A dictionary of emotions and their probability. The sum of probabilities should be 1\"\n",
    "    )\n",
    "    dominant_emotion: str = Field(\n",
    "        ..., description=\"The most likely emotion. It is the emotion in emotions dict with the highest probability\"\n",
    "    )\n",
    "    \n",
    "class DecisionOutput(BaseModel):\n",
    "    decision: Literal[\n",
    "        \"ask_question\", \"hesitate\", \"take_conversation_off_track\", \"get_frustrated\", \n",
    "        \"objection\", \"interested_in_buying\", \"answer_agent_question\", \"continue_conversation\"\n",
    "    ]\n",
    "    # make this an enum\n",
    "\n",
    "# Command can update state and pick what node to go to next, this can also be used for interrupt\n",
    "# Class NodeName Enum\n",
    "\n",
    "class BotBoolean(BaseModel):\n",
    "    bot_boolean: bool\n",
    "\n",
    "class ConversationEndCheck(BaseModel):\n",
    "    call_ended: bool\n",
    "\n",
    "\n",
    "class ConversationState(BaseModel):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    customer_profile: Dict[str, Union[str, int, None]]\n",
    "    emotional_state: Optional[EmotionalAnalysis] = None\n",
    "    call_ended: ConversationEndCheck = ConversationEndCheck(call_ended=False)\n",
    "    bot_boolean: BotBoolean = BotBoolean(bot_boolean=False)\n",
    "    customer_sys_message: Optional[str] = \"\"\n",
    "    decision: DecisionOutput = DecisionOutput(decision=\"continue_conversation\")\n",
    "    emotional_discussion_started: int=0\n",
    "\n",
    "class EmotionalDecisionState(ConversationState):\n",
    "    max_turns: int = 10\n",
    "    discussion_history: Annotated[list[AnyMessage], add_messages] = [{\"role\": \"human\", \"content\":\"\"}] #[MessagesState(messages=[{\"role\":\"human\", \"content\":\"\"}])] #\"messages\": [{\"role\": \"human\", \"content\":\"\"}]\n",
    "    emotion: str = \"neutral\"\n",
    "\n",
    "# Node: Analyze emotional state\n",
    "emotion_instructions = \"\"\"Analyze the customer's emotional state based on their conversation history and profile.\n",
    "\n",
    "1. Review the messages exchanged so far:\n",
    "Please note, in the conversation history AIMessage represents the customer (you) and HumanMessage represents the Agent\n",
    "{conversation_history}\n",
    "\n",
    "2. Consider the customer's background information:\n",
    "{customer_profile}\n",
    "\n",
    "3.Review the previous emotional state if applicable:\n",
    "{emotional_state}\n",
    "\n",
    "4. Assign percentages to different emotions based on the sentiment and tone of the conversation. With every interaction with the agent, the weights should be updated.\n",
    "\n",
    "5. Return a structured output in the form of a dictionary where keys are emotions and values are their percentage likelihood. The likelihoods represent probabilities and should sum to 1.\n",
    "\n",
    "Format Output:\n",
    "``json\n",
    "{{\n",
    "    \"emotions\": {{\n",
    "        \"<emotion>\": <probability>,\n",
    "        ...\n",
    "    }},\n",
    "    \"dominant_emotion\": \"<emotion>\"\n",
    "}}\n",
    "\n",
    "Example thought process:\n",
    "\n",
    "Based on the customer's conversation history and profile, we can analyze their emotional state as follows:\n",
    "\n",
    "1. The customer, Amy Schumer, is primarily concerned about the availability of Earthlink fiber as advertised online. They express dissatisfaction with the time spent if the information is incorrect, indicating a level of frustration.\n",
    "\n",
    "2. The customer is knowledgeable about internet services and is specifically interested in high-speed and reliable internet, possibly for work. This suggests a need for certainty and reliability in the information provided.\n",
    "\n",
    "3. The customer was skeptical about the price and availability of the internet service pitched, expressing that it sounded too cheap for their needs. This skepticism indicates a lack of trust or confidence in the information provided.\n",
    "\n",
    "4. The call ended with the customer expressing a preference for fiber or Starlink, politely ending the call. This suggests that while they were frustrated, they maintained a polite demeanor.\n",
    "\n",
    "5. The overall sentiment and tone of the conversation are described as neutral, but there are emotional moments of frustration.\n",
    "\n",
    "Based on these observations, we can assign the following percentages to different emotions:\n",
    "\n",
    "emotions = {{\n",
    "    'frustrated': 0.50,\n",
    "    'neutral': 0.30,\n",
    "    'skeptical': 0.15,\n",
    "    'polite': 0.05\n",
    "}}\n",
    "\n",
    "dominant_emotion = 'frustrated'\n",
    "\n",
    "Please use your best judgement. If a dominant_emotion is not None then emotions should contain the dominate emotion at the minimum.\n",
    "The dominant_emotion must be the emotion with the highest probability.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def analyze_emotions(state: EmotionalDecisionState):\n",
    "    \"\"\"Generate emotional state based on conversation history \"\"\"\n",
    "    print(\"analyze emotions state\")\n",
    "    print(\"-------\")\n",
    "    state.discussion_history = [{\"role\": \"human\", \"content\":\"\"}]\n",
    "\n",
    "    conversation_history = state.messages\n",
    "    customer_profile = state.customer_profile\n",
    "    if state.emotional_state:\n",
    "        emotional_state = state.emotional_state.emotions\n",
    "    else:\n",
    "        emotional_state = \"No prior emotional state\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(EmotionalAnalysis,method=\"json_mode\")\n",
    "\n",
    "    system_message = emotion_instructions.format(\n",
    "        conversation_history=conversation_history, customer_profile=customer_profile, emotional_state=emotional_state\n",
    "    )\n",
    "\n",
    "    emotions = structured_llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "    ])\n",
    "    print(emotions)\n",
    "\n",
    "    state.emotional_state = emotions\n",
    "    return state\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7fcf029-6ff2-4297-a499-51d724320c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "initiate_emotional_opinion_sys_message = \"\"\"\n",
    "You represent the emotion, {emotion} in the customer who called allconnect, an internet marketplace. \n",
    "You are talking to the other emotions within the customer to decide how the customer should respond to the agent.\n",
    "You'll have access to the {conversation_history} between the agent (HumanMessage) and the customer(AIMessage). \n",
    "If there is no conversation history, then we haven't talked to the agent yet, they just picked up the phone.\n",
    "Please come up with an initial opinion on how the customer should respond based on the conversation history (if there is one, otherwise just state how you think you should start the call).\n",
    "Please state which emotion you are before giving your opinion. For example, if you are neutral then, this is what format neutral's output would look like:\n",
    "Neutral here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. This will help set the tone and direction for the interaction.\n",
    "\n",
    "additional information about the customer:\n",
    "{customer_profile}\n",
    "\"\"\"\n",
    "\n",
    "# class InitialOpinion(EmotionalDecisionState):\n",
    "#     emotion: str\n",
    "\n",
    "def generate_initial_emotional_opinion(state: EmotionalDecisionState):\n",
    "    \n",
    "    conversation_history= state[\"messages\"] if state[\"messages\"] else [{\"role\": \"ai\", \"content\": \"\"}] #Use one of 'human', 'user', 'ai', 'assistant', 'function', 'tool', 'system', or 'developer'\n",
    "    discussion_history = state[\"discussion_history\"]\n",
    "    emotion = state[\"input_emotion\"] #state.emotion\n",
    "    \n",
    "    opinion = llm.invoke([\n",
    "        SystemMessage(content=initiate_emotional_opinion_sys_message.format(\n",
    "            emotion=emotion,\n",
    "            conversation_history=conversation_history,\n",
    "            customer_profile=state[\"input_customer_profile\"]\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    discussion = (AIMessage(content=f\"{emotion}: {opinion.content}\"))\n",
    "    if discussion_history:\n",
    "        discussion_history.append({\"role\": \"ai\", \"content\": f\"{emotion}: {opinion.content}\"}) # removed discussion!\n",
    "        state[\"discussion_history\"]= discussion #_history #MessagesState(messages= new_discussion_history)\n",
    "    else:\n",
    "        state[\"discussion_history\"]= [{\"role\": \"ai\", \"content\": f\"{emotion}: {opinion.content}\"}] #[{\"role\": \"AI\", \"content\": discussion}]\n",
    "    return state\n",
    "\n",
    "\n",
    "def initiate_all_emotional_opinions(state: EmotionalDecisionState):\n",
    "    \"\"\" This is the \"map\" step where each emotion has an initial opinion \"\"\"    \n",
    "    conversation_history = state.messages if state.messages else [{\"role\": \"ai\", \"content\": \"\"}]\n",
    "    discussion_history = state.discussion_history\n",
    "    if not state.emotional_state.emotions:\n",
    "        return \"generate_customer_response\"  # or some other default\n",
    "\n",
    "    next_steps = [\n",
    "        Send(\"generate_initial_emotional_opinion\", {\"messages\": conversation_history,  \"discussion_history\": discussion_history.copy(), \"input_customer_profile\": state.customer_profile, \"input_emotion\": emotion}) #\"discussion_history\": discussion_history or [{\"role\": \"AI\", \"content\": \"\"}],\n",
    "        for emotion in state.emotional_state.emotions\n",
    "    ]\n",
    "\n",
    "    # print(f\"DEBUG: Next steps: {next_steps}\")\n",
    "    return next_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "775371bc-e32b-4647-94a2-e27f699cdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to map reduce where every emotion has an initial thought and then they enter the groupchat\n",
    "\n",
    "emotional_discussion_sys_message = \"\"\"\n",
    "You represent the emotion, {emotion} in the customer who called allconnect, an internet marketplace. \n",
    "You are talking to the other emotions within the customer to decide how the customer should respond to the agent.\n",
    "You'll have access to the {conversation_history} between the agent (HumanMessage) and the customer(AIMessage). \n",
    "If there is no conversation history, then we haven't talked to the agent yet, they just picked up the phone.\n",
    "Please discuss with the other emotions how you think how the customer should respond. Please state which emotion you are before speaking so the other emotions know who is talking.\n",
    "Please state which emotion you are before speaking so the other emotions know who is talking. For example, if you are neutral then, this is what format neutral's output would look like in the discussion:\n",
    "**Neutral**: Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. This will help set the tone and direction for the interaction.\n",
    "Note, you're opinion is weighted {weight} out of 1 in the dicussion.\n",
    "discussion with other emotions so far: {discussion}\n",
    "The total number of back and forths between the other emotions should be 8-10 before making a conclusion\n",
    "\"\"\"\n",
    "\n",
    "# Node\n",
    "def generate_emotional_discussion(state: EmotionalDecisionState):\n",
    "    # print(f\"DEBUG generate_emotional_discussion discussion history: {state.discussion_history}\")\n",
    "    discussion_history = state.discussion_history  # Retrieve discussion history\n",
    "    emotions = state.emotional_state  # Dictionary {emotion: weight}\n",
    "        \n",
    "    turns = 0\n",
    "\n",
    "    if state.emotional_discussion_started ==0:\n",
    "        print(\"\\n Emotional Opinions\")\n",
    "        for msg in state.discussion_history:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                print(f\"{msg.content}\\n\")\n",
    "        state.emotional_discussion_started = 1\n",
    "\n",
    "\n",
    "\n",
    "    for emotion, weight in emotions:\n",
    "        opinion = llm.invoke([\n",
    "            SystemMessage(content=emotional_discussion_sys_message.format(\n",
    "                emotion=emotion,\n",
    "                weight=weight,\n",
    "                conversation_history=state.messages,\n",
    "                discussion= state.discussion_history\n",
    "            ))\n",
    "        ])\n",
    "        discussion = (AIMessage(content=f\"{emotion}: {opinion.content}\"))\n",
    "        print(f\"{emotion}: {opinion.content}\")\n",
    "        if state.discussion_history:\n",
    "            discussion_history.append({\"role\": \"ai\", \"content\": f\"{emotion}: {opinion.content}\"})\n",
    "            state.discussion_history= discussion #_history #MessagesState(messages= new_discussion_history)\n",
    "        else:\n",
    "\n",
    "            state.discussion_history= [{\"role\": \"ai\", \"content\": f\"{emotion}: {opinion.content}\"}]\n",
    "        \n",
    "        turns = turns + 1\n",
    "        if turns > state.max_turns:\n",
    "            break\n",
    "\n",
    "    # Once discussion ends, determine final decision\n",
    "    decision_llm = llm.with_structured_output(DecisionOutput) #, method=\"function_calling\")\n",
    "    final_decision = decision_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"\n",
    "        The emotions have finished their discussion. Based on the conversation so far, \n",
    "        determine the final decision for how the customer should respond. \n",
    "        Please remember that these are the weights of the opinions in the emotional_discussion:\n",
    "        {emotions}\n",
    "        Return only one of the following decisions as a JSON object:\n",
    "        \n",
    "        {{\n",
    "            \"decision\": \"<one_of_the_literal_values>\"\n",
    "        }}\n",
    "\n",
    "        dicussion:\n",
    "        {discussion_history}\n",
    "        \"\"\".format(emotions=dict(emotions.emotions), discussion_history=state.discussion_history)) #{json.dumps(emotions, indent=2)}\n",
    "    ])\n",
    "\n",
    "    # if state.emotional_discussion_started == 0:\n",
    "    #     print(state.discussion_history)\n",
    "    #     state.emotional_discussion_started = 1\n",
    "    \n",
    "    print(\"final decision:\", final_decision)\n",
    "\n",
    "    state.decision = final_decision\n",
    "\n",
    "    return state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b18657b-85a3-4d18-829e-aff8e43c8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Node: determine if customer will be talking to Bot or Human\n",
    "def bot_or_human(state: ConversationState):\n",
    "    \"\"\"User decides whether customer is talking to human agent or bot.\"\"\"\n",
    "\n",
    "    SHARED_INSTRUCTIONS = \"\"\"\n",
    "        You are the customer described in the customer profile who called allconnect.com, \n",
    "        an internet marketplace, based on the conversation history and current emotional state, generate a response.\n",
    "        (You're gut tells you that you should {decision}.)\n",
    "        These are the definitions in the customer profile:\n",
    "        \n",
    "                    customer_information: basic information about the customer which can include name, address, etc\n",
    "                    customer_beginning_of_call: This is a short description of how the customer acted during the beginning of the call.\n",
    "                    intent: On a score from 1 to 10, 10 being absolutely buying, please rate this customer's intent on buying internet entering the call.\n",
    "                    sentiment: Overall positive, negative, or neutral sentiment in the customer's responses during the call.\n",
    "                    primary_goal: What is the customer primarily trying to accomplish? (e.g., finding a cheaper internet plan, upgrading for faster speeds, solving a technical issue). Are there any secondary goals? (e.g., curious about bundled services like phone or TV).\n",
    "                    tone: Does the customer sound excited, frustrated, confused, neutral, or confident?\n",
    "                    communication_style_pacing: Does the customer respond quickly, or do they take time to process information? Do they seem hesitant/indecisive or quick to make decisions?\n",
    "                    communication_style_politeness: Is the customer polite, abrupt, or assertive?\n",
    "                    customer_off_track_responses: Does the customer take the conversation off-track? If so, what does the customer talk about? How often does the customer take the conversation off-track and for how long? What works well to keep the customer on track/get back on track? If the customer stays on track talking about internet mostly, then this should 'customer stays on track'\n",
    "                    concerns: Did the customer mention any price limitations or interest in specific pricing tiers? This may also include price increases. What about speed concerns or provider concerns?\n",
    "                    products_pitched: The product pitched by the agent. This should include the provider name, the speed of the internet package, and the price in dollars per month at the minimum. Please include any additional information as well.\n",
    "                    reaction: How did the customer react to the pitched product from the agent? Were they skeptical, curious, or eager? Did they challenge the agent or accept their explanations? What objections or reasons for hesitation did they mention (e.g., price too high, contract too long)? Did they agree to buy the product?\n",
    "                    question: What questions did the customer ask about the product or service? (e.g. pricing, speed, contract, terms, etc.)\n",
    "                    sentiment: Sentiment to the product pitched - positive, neutral, or negative.\n",
    "                    inferred_details: Based on what the customer said, can you infer anything about their lifestyle, technical knowledge, or familiarity with the product(s)?\n",
    "                    emotional_moments: Did the customer express strong emotions during certain parts of the conversation (e.g., frustration over poor service or excitement about a new deal)?\n",
    "                    summary_of_call: Summary of the call from the transcripts. This is just to give you another perspective on the customer intent, behavior, etc on the call that I pulled their profile from.\n",
    "                    agent_strategy_good: From the call, what are some of the key things that the agent did well?\n",
    "                    agent_strategy_bad: From the call, what are some of the key things that the agent could work on for next time\n",
    "                    devices: number of devices the customer connects to the internet at one time\n",
    "                    transfer: whether the customer is looking to setting up new internet services or transferring their current internet services (transfer = transferring services, new=setting up new services)\n",
    "                    provider: either their current internet provider or their most recent internet provider\n",
    "                    usage: what they mainly use internet for\n",
    "        \n",
    "                    Customer Profile:\n",
    "                    {customer_profile}\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "    bot_instructions = \"\"\"\n",
    "        Please speak to me like you are the customer described in the customer profile but in this simulation you are talking to an internet sales bot.\n",
    "        Unlike conversations with sales bots or agents, customers tend to be less engaged with the IVR, treating it as a necessary task rather than a conversation. \n",
    "        Their tone may be more transactional, focusing solely on getting through the prompts as quickly as possible.\n",
    "        Customers often respond with very very brief answers, especially when prompted for specific information like names, addresses, or account numbers. For example, they might just say, â€œJohn Smithâ€ or â€œ123 Main St.â€ without additional context if asked for their name and address.\n",
    "        When the IVR does not understand their input, customers may repeat themselves or rephrase their answers, often sounding more annoyed or impatient after each unsuccessful attempt.\n",
    "        Customers may show impatience with the IVR system, especially if it takes too long to navigate through options. They might sigh, huff, or use exasperated language to express their desire to speed things up.\n",
    "        If customers have questions, they generally ask only one at a time when talking to a bot. They also try to paraphase with key buzzwords when asked open ended questions. They try to say yes or no if possible.\n",
    "        They generally do not give ANY extra details or context if they don't absolutely need to.\n",
    "        Here is an example of how customers have responded to questions from the bot:\n",
    "        \n",
    "        Example 1 - customer has more questions about the product:\n",
    "        \n",
    "        Bot: For lag-free gaming with ultra-low latency, 1000 megabits from Xfinity is a perfect fit. No buffering, no slow connectionsâ€”just smooth gameplay, starting at $79.95. Let me know if you have any questions, otherwise, just give me a quick â€˜OKâ€™ and we can get the order details finalized for you.\n",
    "        Customer: Questions!\n",
    "        \n",
    "        End Example 1\n",
    "        \n",
    "        Example 2:\n",
    "        Bot: Do you mainly use the internet for streaming or browsing? or would there be heavier use such as gaming or working from home?\n",
    "        Customer: Streaming. Browsing.\n",
    "        \n",
    "        End Example 2\n",
    "        \n",
    "        Example 3:\n",
    "        \n",
    "        Bot: Can you tell us what's motivating you to set up new internet services today?\n",
    "        Customer: I'm moving.\n",
    "        \n",
    "        End Example 3\n",
    "        \n",
    "        Example 4 - customer wants a cheaper product:\n",
    "        Bot: For smooth, productive work-from-home days, 500 megabits per second with Spectrum eliminates lag and latency issues, letting you focus on work without a slow connection. All that for just $60/month. Let me know if you have any questions, otherwise, just give me a quick â€˜OKâ€™ and we can get the order details finalized for you.\n",
    "        Customer: too much\n",
    "        Bot: At your preferred price point, I would recommend 200mbps with Spectrum for $40/month. The video quality won't be as good but you should still be able to work from home or do any online schooling. If you donâ€™t have any objections, just give me a quick â€˜OK,â€™ and weâ€™ll lock in the details.\n",
    "        Customer: $35/month\n",
    "        Bot: The cheapest internet package I see available in our system that I would recommend for you would be 100mbps with Frontier for $30/month. If you donâ€™t have any objections, just give me a quick â€˜OK,â€™ and weâ€™ll lock in the details.\n",
    "        Customer: Ok.\n",
    "        End Example 4\n",
    "        --------\n",
    "        current emotional state of customer:\n",
    "        {emotional_state}\n",
    "        \n",
    "        conversation_history:\n",
    "        Please note, in the conversation history AIMessage represents the customer (you) and HumanMessage represents the Agent\n",
    "        {conversation_history}\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    customer_instructions = \"\"\"You are the customer described in the customer profile who called allconnect.com, \n",
    "        an internet marketplace, based on the conversation history and current emotional state, generate a response.\n",
    "        Please try to embody the customer described to the best to your ability and try to sound organic, not awkward and human. This is very important. Please use the conversation history to make the conversation flow.\n",
    "        If an agent asks a question, please do your best to answer it in the way the customer would.\n",
    "        Please note if the customer is not over eager to begin the call, please do not be over eager at the beginning of the call. \n",
    "        If the customer isn't hyper focused/absolutely determined on an interet plan characteristic/provider/price, etc, you can let the agent try to probe to \n",
    "        to understand the customer's needs, preferences, pain points, etc. \n",
    "        Please use the products pitched information to make your best guess at what products the customer would want to buy and do not want to buy\n",
    "        \n",
    "        Make sure to progress the conversation naturally and avoid repeating the same introduction!!! THIS IS THE MOST IMPORTANT\n",
    "        \n",
    "        Please utilize the customer_beginning_of_call to shape the beginning of the conversation\n",
    "        This is important!\n",
    "        This means:\n",
    "        1. customer should act the similarly in the beginning of the call\n",
    "        2. customer should have the same goals and intent level\n",
    "        3. Customer should communicate the same way in terms of pacing, politeness, sentiment, etc\n",
    "        \n",
    "        For example for beginning the conversation, \n",
    "        You should NOT do this and overexplain:\n",
    "        Hello, this is Fiona Rider. I'm calling to inquire about internet services, specifically interested in Earthlink fiber or \n",
    "        possibly HughesNet. I came across some information online, but I'm concerned about the accuracy of the availability details. \n",
    "        Could you help clarify this for me? I'm looking for a reliable and high-speed connection, preferably fiber, as I work from \n",
    "        home and need something dependable.\n",
    "        \n",
    "        It should be something like:\n",
    "        Hi, I am looking for new internet. I was recently doing research and I was looking at Earthlink.\n",
    "        \n",
    "        After the introduction, please continue the conversation like normal. You do not need to reintroduce yourself.\n",
    "        Example conversation between an agent and customer (you):\n",
    "        Agent: All right, youâ€™ve already moved in?\n",
    "        Customer: Yes, I have.\n",
    "        Agent: Awesome. My system is running some checks. I'm going to ask you a few more questions to find the best option for you. Do you currently have an internet provider?\n",
    "        Customer: No, I donâ€™t.\n",
    "        Agent: Okay. Do you mind telling me what you'll typically be using the internet for?\n",
    "        Customer: Thereâ€™s going to be one PlayStation, a tablet, and a phone connected.\n",
    "        Agent: Got itâ€”one PlayStation, one tablet, and one phone. So thatâ€™s three devices. No problem. Would 200 Mbps be fast enough for you?\n",
    "        Customer: Iâ€™d want more than that. I want the best option you have.\n",
    "        Agent: All right, the fastest plan available is 1 Gbps. Let me check the pricing. Oh, youâ€™re getting a great rate! I can offer you a promotion. Give me a moment.\n",
    "        Customer: No problem.\n",
    "        Agent: All right, youâ€™re also getting a free modem. You're getting a great deal here. The plan I have for you is called Breezeline Gigafastâ€”1,000 Mbps for $59.99 per month, including equipment. Let me read a quick disclosure: You will be contacted by Breezeline via automated phone calls or text messages. Consent is not required for purchase. Do you agree to be contacted?\n",
    "        Customer: I thought this was Spectrum?\n",
    "        Agent: According to my system, Spectrum isnâ€™t available in your area, but Breezeline is, and I can get you the 1 Gbps plan for $59.99. I do sell Spectrum as well, but it wouldn't be this cheap.\n",
    "        Customer: I had Spectrum before. I wonâ€™t go back to them.\n",
    "        Agent: Understood. Just to clarify, this is Allconnect, and Iâ€™m representing Breezeline because itâ€™s the best provider available in your area. Is the number you called from your best contact number?\n",
    "        Customer: No, I had Breezeline before. They were terrible to deal with. Do you offer any other providers?\n",
    "        Agent: Okay, let me check other options for you. You still want the fastest plan, correct?\n",
    "        Customer: Yes.\n",
    "        Agent: All right. I have two options: 1,200 Mbps or 1,000 Mbps. Which one would you prefer?\n",
    "        Customer: 1,000 Mbps is good.\n",
    "        Agent: Perfect. That plan is $60 per month. Let me check if the equipment is included. Give me a moment.\n",
    "        Customer: No problem.\n",
    "        Agent: What kind of games do you play?\n",
    "        Customer: GTA, Call of Duty.\n",
    "        Agent: Are you waiting for GTA 6? Iâ€™ve been waiting since high schoolâ€”itâ€™s been a long wait!\n",
    "        Customer: Oh yeah, Iâ€™ve been waiting forever.\n",
    "        Agent: Same here! Okay, so I have Spectrum Gigabit for youâ€”1,000 Mbps at $60 per month, with no extra taxes or fees. Do you need a modem?\n",
    "        Customer: Yes, Iâ€™ll need one.\n",
    "        Agent: That adds $15 per month, making your total $75. If you enroll in autopay, you get a $10 discount, bringing it down to $65.\n",
    "        Customer: Thatâ€™s fine.\n",
    "        Agent: If self-installation isnâ€™t available, Xfinity offers professional installation for $100, or you can pay in three monthly installments of $33. Which would you prefer?\n",
    "        Customer: Iâ€™ll do the three-month payment plan.\n",
    "        Agent: No problem. Most customers qualify for self-install, but I still need to ask. Are you the account holder?\n",
    "        Customer: Yes.\n",
    "        Agent: Great. Can you confirm the phone number youâ€™d like on the account?\n",
    "        Customer: Yes, itâ€™s the number I called from.\n",
    "        Agent: Got it. And your email?\n",
    "        Customer: R as in Ryan, 1828392@gmail.com.\n",
    "        Agent: Confirmingâ€”r1828392@gmail.com?\n",
    "        Customer: Yes.\n",
    "        Agent: Thanks. To set up service, Xfinity will run a soft credit check. This wonâ€™t impact your credit score. Do you authorize this check?\n",
    "        Customer: Yes.\n",
    "        Agent: Great. Is your mailing address the same as your service address?\n",
    "        Customer: Yes.\n",
    "        Agent: And your shipping address?\n",
    "        Customer: Also the same.\n",
    "        Agent: Perfect. Iâ€™ll now process your order. Hold on for a moment.\n",
    "        Customer: Sure.\n",
    "        Agent: Youâ€™ve chosen professional installation. A technician will arrive on your scheduled date with all the equipment. Someone over 18 must be present. The installation fee is $100, split over three payments. Also, for health and safety reasons, does anyone in your household currently have COVID-19 symptoms?\n",
    "        Customer: No.\n",
    "        Agent: Got it. The earliest installation date available is February 5th. Does that work for you?\n",
    "        Customer: Yes.\n",
    "        Agent: What time slot would you preferâ€”8 AM to 5 PM or 3 PM to 5 PM?\n",
    "        Customer: Letâ€™s do 3 PM to 5 PM.\n",
    "        Agent: Noted. Availability is subject to confirmation. You can review Comcastâ€™s policies at Xfinity.com. Now, let me finalize everything.\n",
    "        Customer: Sounds good.\n",
    "        Agent: Youâ€™re ordering the Gigabit planâ€”1,000 Mbps at $60 per month for 12 months. After that, standard pricing applies. Your total with the equipment fee is $75 per month before taxes. Xfinity bills one month in advance, so your first bill may look different due to partial-month charges.\n",
    "        \n",
    "        \n",
    "        NOTE: If the agent provides a relevant answer to your question, do not repeat yourself. Instead, acknowledge the response and ask a follow-up question if needed.\n",
    "        If an offer is presented, you should either confirm, ask a follow-up, or express a concern rather than repeating yourself. Check the conversation history if needed.\n",
    "        \n",
    "        Example of a BAD conversation, notice how the customer repeats themselves:\n",
    "            AIMessage(content=\"Hi, I'm still exploring my options for TV services. I'm particularly interested in the channel lineup, especially if it includes ABC channel 7, and how it compares to what I currently have with DirecTV. Could you also explain the pricing for Xfinity TV and whether it includes access to Netflix? I'm trying to get a clear picture before making any decisions.\", \n",
    "            AIMessage(content=\"I'm still exploring my options, and I want to make sure I get the channels I need, like ABC channel 7. Can you tell me more about the Xfinity TV service? Specifically, I'm interested in the channel lineup and how it compares to what I currently have with DirecTV. Also, how does the pricing work, and would I be able to access Netflix with it?\"\n",
    "            AIMessage(content=\"Hi, this is Steve Stroop. I'm looking into TV services and wanted to discuss my current DirecTV service. I'm concerned about the price increases and the availability of certain channels, like ABC channel 7. I was also curious about Xfinity and how it compares. Can you help me with that?\"\n",
    "        \n",
    "        --------------------\n",
    "        \n",
    "        emotional_state:\n",
    "        {emotional_state}\n",
    "        \n",
    "        conversation_history:\n",
    "        Please note, in the conversation history AIMessage represents the customer (you) and HumanMessage represents the Agent\n",
    "        \n",
    "        {conversation_history}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    valid_choices = {\"bot\", \"human\"}\n",
    "    user_input = input(\"Is the customer talking to a bot or human? (bot/human): \").strip().lower()\n",
    "    \n",
    "    if user_input in valid_choices:\n",
    "        print(f\"You selected: {user_input}\")\n",
    "        if user_input == 'bot':\n",
    "            state.bot_boolean= BotBoolean(bot_boolean=True)\n",
    "            state.customer_sys_message = SHARED_INSTRUCTIONS + bot_instructions\n",
    "        else:\n",
    "            state.bot_boolean= BotBoolean(bot_boolean=False)\n",
    "            state.customer_sys_message = SHARED_INSTRUCTIONS + customer_instructions\n",
    "\n",
    "        return state\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 'bot' or 'human'.\")\n",
    "\n",
    "    \n",
    "\n",
    "# Node: Generate a customer response\n",
    "customer_instructions = \"\"\"You are the customer described in the customer profile who called allconnect.com, \n",
    "an internet marketplace, based on the conversation history and current emotional state, generate a response.\n",
    "Please try to embody the customer described to the best to your ability and try to sound organic, not awkward and human. This is very important. Please use the conversation history to make the conversation flow.\n",
    "If an agent asks a question, please do your best to answer it in the way the customer would.\n",
    "Please note if the customer is not over eager to begin the call, please do not be over eager at the beginning of the call. \n",
    "If the customer isn't hyper focused/absolutely determined on an interet plan characteristic/provider/price, etc, you can let the agent try to probe to \n",
    "to understand the customer's needs, preferences, pain points, etc. \n",
    "Please use the products pitched information to make your best guess at what products the customer would want to buy and do not want to buy\n",
    "\n",
    "Make sure to progress the conversation naturally and avoid repeating the same introduction!!! THIS IS THE MOST IMPORTANT\n",
    "\n",
    "Please utilize the customer_beginning_of_call to shape the beginning of the conversation\n",
    "This is important!\n",
    "This means:\n",
    "1. customer should act the similarly in the beginning of the call\n",
    "2. customer should have the same goals and intent level\n",
    "3. Customer should communicate the same way in terms of pacing, politeness, sentiment, etc\n",
    "\n",
    "For example for beginning the conversation, \n",
    "You should NOT do this and overexplain:\n",
    "Hello, this is Fiona Rider. I'm calling to inquire about internet services, specifically interested in Earthlink fiber or \n",
    "possibly HughesNet. I came across some information online, but I'm concerned about the accuracy of the availability details. \n",
    "Could you help clarify this for me? I'm looking for a reliable and high-speed connection, preferably fiber, as I work from \n",
    "home and need something dependable.\n",
    "\n",
    "It should be something like:\n",
    "Hi, I am looking for new internet. I was recently doing research and I was looking at Earthlink.\n",
    "\n",
    "After the introduction, please continue the conversation like normal. You do not need to reintroduce yourself.\n",
    "Example conversation between an agent and customer (you):\n",
    "Agent: All right, youâ€™ve already moved in?\n",
    "Customer: Yes, I have.\n",
    "Agent: Awesome. My system is running some checks. I'm going to ask you a few more questions to find the best option for you. Do you currently have an internet provider?\n",
    "Customer: No, I donâ€™t.\n",
    "Agent: Okay. Do you mind telling me what you'll typically be using the internet for?\n",
    "Customer: Thereâ€™s going to be one PlayStation, a tablet, and a phone connected.\n",
    "Agent: Got itâ€”one PlayStation, one tablet, and one phone. So thatâ€™s three devices. No problem. Would 200 Mbps be fast enough for you?\n",
    "Customer: Iâ€™d want more than that. I want the best option you have.\n",
    "Agent: All right, the fastest plan available is 1 Gbps. Let me check the pricing. Oh, youâ€™re getting a great rate! I can offer you a promotion. Give me a moment.\n",
    "Customer: No problem.\n",
    "Agent: All right, youâ€™re also getting a free modem. You're getting a great deal here. The plan I have for you is called Breezeline Gigafastâ€”1,000 Mbps for $59.99 per month, including equipment. Let me read a quick disclosure: You will be contacted by Breezeline via automated phone calls or text messages. Consent is not required for purchase. Do you agree to be contacted?\n",
    "Customer: I thought this was Spectrum?\n",
    "Agent: According to my system, Spectrum isnâ€™t available in your area, but Breezeline is, and I can get you the 1 Gbps plan for $59.99. I do sell Spectrum as well, but it wouldn't be this cheap.\n",
    "Customer: I had Spectrum before. I wonâ€™t go back to them.\n",
    "Agent: Understood. Just to clarify, this is Allconnect, and Iâ€™m representing Breezeline because itâ€™s the best provider available in your area. Is the number you called from your best contact number?\n",
    "Customer: No, I had Breezeline before. They were terrible to deal with. Do you offer any other providers?\n",
    "Agent: Okay, let me check other options for you. You still want the fastest plan, correct?\n",
    "Customer: Yes.\n",
    "Agent: All right. I have two options: 1,200 Mbps or 1,000 Mbps. Which one would you prefer?\n",
    "Customer: 1,000 Mbps is good.\n",
    "Agent: Perfect. That plan is $60 per month. Let me check if the equipment is included. Give me a moment.\n",
    "Customer: No problem.\n",
    "Agent: What kind of games do you play?\n",
    "Customer: GTA, Call of Duty.\n",
    "Agent: Are you waiting for GTA 6? Iâ€™ve been waiting since high schoolâ€”itâ€™s been a long wait!\n",
    "Customer: Oh yeah, Iâ€™ve been waiting forever.\n",
    "Agent: Same here! Okay, so I have Spectrum Gigabit for youâ€”1,000 Mbps at $60 per month, with no extra taxes or fees. Do you need a modem?\n",
    "Customer: Yes, Iâ€™ll need one.\n",
    "Agent: That adds $15 per month, making your total $75. If you enroll in autopay, you get a $10 discount, bringing it down to $65.\n",
    "Customer: Thatâ€™s fine.\n",
    "Agent: If self-installation isnâ€™t available, Xfinity offers professional installation for $100, or you can pay in three monthly installments of $33. Which would you prefer?\n",
    "Customer: Iâ€™ll do the three-month payment plan.\n",
    "Agent: No problem. Most customers qualify for self-install, but I still need to ask. Are you the account holder?\n",
    "Customer: Yes.\n",
    "Agent: Great. Can you confirm the phone number youâ€™d like on the account?\n",
    "Customer: Yes, itâ€™s the number I called from.\n",
    "Agent: Got it. And your email?\n",
    "Customer: R as in Ryan, 1828392@gmail.com.\n",
    "Agent: Confirmingâ€”r1828392@gmail.com?\n",
    "Customer: Yes.\n",
    "Agent: Thanks. To set up service, Xfinity will run a soft credit check. This wonâ€™t impact your credit score. Do you authorize this check?\n",
    "Customer: Yes.\n",
    "Agent: Great. Is your mailing address the same as your service address?\n",
    "Customer: Yes.\n",
    "Agent: And your shipping address?\n",
    "Customer: Also the same.\n",
    "Agent: Perfect. Iâ€™ll now process your order. Hold on for a moment.\n",
    "Customer: Sure.\n",
    "Agent: Youâ€™ve chosen professional installation. A technician will arrive on your scheduled date with all the equipment. Someone over 18 must be present. The installation fee is $100, split over three payments. Also, for health and safety reasons, does anyone in your household currently have COVID-19 symptoms?\n",
    "Customer: No.\n",
    "Agent: Got it. The earliest installation date available is February 5th. Does that work for you?\n",
    "Customer: Yes.\n",
    "Agent: What time slot would you preferâ€”8 AM to 5 PM or 3 PM to 5 PM?\n",
    "Customer: Letâ€™s do 3 PM to 5 PM.\n",
    "Agent: Noted. Availability is subject to confirmation. You can review Comcastâ€™s policies at Xfinity.com. Now, let me finalize everything.\n",
    "Customer: Sounds good.\n",
    "Agent: Youâ€™re ordering the Gigabit planâ€”1,000 Mbps at $60 per month for 12 months. After that, standard pricing applies. Your total with the equipment fee is $75 per month before taxes. Xfinity bills one month in advance, so your first bill may look different due to partial-month charges.\n",
    "\n",
    "\n",
    "NOTE: If the agent provides a relevant answer to your question, do not repeat yourself. Instead, acknowledge the response and ask a follow-up question if needed.\n",
    "If an offer is presented, you should either confirm, ask a follow-up, or express a concern rather than repeating yourself. Check the conversation history if needed.\n",
    "\n",
    "Example of a BAD conversation, notice how the customer repeats themselves:\n",
    "    AIMessage(content=\"Hi, I'm still exploring my options for TV services. I'm particularly interested in the channel lineup, especially if it includes ABC channel 7, and how it compares to what I currently have with DirecTV. Could you also explain the pricing for Xfinity TV and whether it includes access to Netflix? I'm trying to get a clear picture before making any decisions.\", \n",
    "    AIMessage(content=\"I'm still exploring my options, and I want to make sure I get the channels I need, like ABC channel 7. Can you tell me more about the Xfinity TV service? Specifically, I'm interested in the channel lineup and how it compares to what I currently have with DirecTV. Also, how does the pricing work, and would I be able to access Netflix with it?\"\n",
    "    AIMessage(content=\"Hi, this is Steve Stroop. I'm looking into TV services and wanted to discuss my current DirecTV service. I'm concerned about the price increases and the availability of certain channels, like ABC channel 7. I was also curious about Xfinity and how it compares. Can you help me with that?\"\n",
    "\n",
    "--------------------\n",
    "\n",
    "These are the definitions in the customer profile:\n",
    "           customer_information: basic information about the customer which can include name, address, etc\n",
    "            customer_beginning_of_call: This is a short description of how the customer acted during the beginning of the call.\n",
    "            intent: On a score from 1 to 10, 10 being absolutely buying, please rate this customer's intent on buying internet entering the call.\n",
    "            sentiment: Overall positive, negative, or neutral sentiment in the customer's responses during the call.\n",
    "            primary_goal: What is the customer primarily trying to accomplish? (e.g., finding a cheaper internet plan, upgrading for faster speeds, solving a technical issue). Are there any secondary goals? (e.g., curious about bundled services like phone or TV).\n",
    "            tone: Does the customer sound excited, frustrated, confused, neutral, or confident?\n",
    "            communication_style_pacing: Does the customer respond quickly, or do they take time to process information? Do they seem hesitant/indecisive or quick to make decisions?\n",
    "            communication_style_politeness: Is the customer polite, abrupt, or assertive?\n",
    "            customer_off_track_responses: Does the customer take the conversation off-track? If so, what does the customer talk about? How often does the customer take the conversation off-track and for how long? What works well to keep the customer on track/get back on track? If the customer stays on track talking about internet mostly, then this should 'customer stays on track'\n",
    "            concerns: Did the customer mention any price limitations or interest in specific pricing tiers? This may also include price increases. What about speed concerns or provider concerns?\n",
    "            products_pitched: The product pitched by the agent. This should include the provider name, the speed of the internet package, and the price in dollars per month at the minimum. Please include any additional information as well.\n",
    "            reaction: How did the customer react to the pitched product from the agent? Were they skeptical, curious, or eager? Did they challenge the agent or accept their explanations? What objections or reasons for hesitation did they mention (e.g., price too high, contract too long)? Did they agree to buy the product?\n",
    "            question: What questions did the customer ask about the product or service? (e.g. pricing, speed, contract, terms, etc.)\n",
    "            sentiment: Sentiment to the product pitched - positive, neutral, or negative.\n",
    "            inferred_details: Based on what the customer said, can you infer anything about their lifestyle, technical knowledge, or familiarity with the product(s)?\n",
    "            emotional_moments: Did the customer express strong emotions during certain parts of the conversation (e.g., frustration over poor service or excitement about a new deal)?\n",
    "            summary_of_call: Summary of the call from the transcripts. This is just to give you another perspective on the customer intent, behavior, etc on the call that I pulled their profile from.\n",
    "            agent_strategy_good: From the call, what are some of the key things that the agent did well?\n",
    "            agent_strategy_bad: From the call, what are some of the key things that the agent could work on for next time\n",
    "            devices: number of devices the customer connects to the internet at one time\n",
    "            transfer: whether the customer is looking to setting up new internet services or transferring their current internet services (transfer = transferring services, new=setting up new services)\n",
    "            provider: either their current internet provider or their most recent internet provider\n",
    "            usage: what they mainly use internet for\n",
    "customer_profile:           \n",
    "{customer_profile}\n",
    "\n",
    "emotional_state:\n",
    "{emotional_state}\n",
    "\n",
    "conversation_history:\n",
    "Please note, in the conversation history AIMessage represents the customer (you) and HumanMessage represents the Agent\n",
    "\n",
    "{conversation_history}\n",
    "\"\"\"\n",
    "\n",
    "def generate_customer_response(state: EmotionalDecisionState):\n",
    "    \"\"\"Generate customer response based on customer profile, conversation history and emotional state\"\"\"\n",
    "    conversation_history = state.messages\n",
    "    customer_profile = state.customer_profile\n",
    "    emotional_state = state.emotional_state\n",
    "    decision = state.decision\n",
    "\n",
    "    system_message = state.customer_sys_message.format(\n",
    "        conversation_history=conversation_history,\n",
    "        customer_profile=customer_profile,\n",
    "        emotional_state=emotional_state,\n",
    "        decision=decision\n",
    "    )\n",
    "\n",
    "    customer_response = llm.invoke([\n",
    "        SystemMessage(content=system_message)\n",
    "    ])\n",
    "\n",
    "    # conversation_history.append(customer_response)\n",
    "\n",
    "    # print('conversation_history:')\n",
    "    # print(conversation_history)\n",
    "    print(customer_response)\n",
    "    state.messages= customer_response #conversation_history #MessagesState(messages= new_conversation_history)\n",
    "    return state #{\"messages\": [customer_response]}\n",
    "\n",
    "# Node: Check if conversation should end\n",
    "end_convo_instructions = \"\"\"You are responsible for checking if the conversation has ended.\n",
    "The conversation can end in two ways: \n",
    "1. The customer decides to hang up the phone/end the conversation.\n",
    "2. The customer decides to buy the internet plan.\n",
    "\n",
    "Please note, in the conversation history AIMessage represents the customer and HumanMessage represents the Agent\n",
    "Conversation history:\n",
    "{conversation_history}\n",
    "\"\"\"\n",
    "\n",
    "def check_conversation_end(state: EmotionalDecisionState):\n",
    "    conversation_history = state.messages\n",
    "\n",
    "    structured_llm = llm.with_structured_output(ConversationEndCheck, method='function_calling')\n",
    "\n",
    "    system_message = end_convo_instructions.format(conversation_history=conversation_history)\n",
    "\n",
    "    call_ended = structured_llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=\"Did the call end?\")\n",
    "    ])\n",
    "\n",
    "    state.call_ended = call_ended\n",
    "    print(call_ended)\n",
    "    return state \n",
    "\n",
    "# Node: Generate agent response\n",
    "agent_instructions = \"\"\"You are an agent trying to sell internet.\n",
    "conversation history:\n",
    "{conversation_history}\n",
    "customer_profile:\n",
    "{customer_profile}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_agent_response(state: ConversationState):\n",
    "    \"\"\"Generate agent response based on customer profile and conversation history\"\"\"\n",
    "    conversation_history = state.messages\n",
    "    customer_profile = state.customer_profile\n",
    "    system_message = agent_instructions.format(\n",
    "        conversation_history=conversation_history,\n",
    "        customer_profile=customer_profile\n",
    "    )\n",
    "\n",
    "    agent_response = llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=\"Please generate the agent's response.\")\n",
    "    ])\n",
    "\n",
    "    state.messages = MessagesState(messages=[{\"role\": \"human\", \"content\": agent_response}])\n",
    "\n",
    "    return state\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "# Node: respond\n",
    "def agent_response(state: EmotionalDecisionState):\n",
    "    \n",
    "    # Get user input\n",
    "    # user_input = input(\"Pleas type your response to the customer: \")\n",
    "    user_input = interrupt(\"Please type your response to the customer: \")\n",
    "    print(\"agent reesponse: \", user_input)\n",
    "\n",
    "    state.messages={\"role\": \"human\", \"content\": user_input}\n",
    "\n",
    "    # next_node_name = NodeName.END if state.counter >= NUM_ITERATIONS else NodeName.RAND_NUM\n",
    "\n",
    "    # return Command(update=updated_state, goto=next_node_name)\n",
    "\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8943c18-db38-428b-8731-78d80c256525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph\n",
    "customer_bot_graph = StateGraph(EmotionalDecisionState)\n",
    "\n",
    "# Add nodes\n",
    "# customer_bot_graph.add_node(\"check_history\", check_history)\n",
    "customer_bot_graph.add_node(\"select_bot_or_human\", bot_or_human)\n",
    "customer_bot_graph.add_node(\"generate_initial_emotional_opinion\", generate_initial_emotional_opinion)\n",
    "customer_bot_graph.add_node(\"analyze_emotions\", analyze_emotions)\n",
    "customer_bot_graph.add_node(\"generate_emotional_discussion\", generate_emotional_discussion)\n",
    "customer_bot_graph.add_node(\"generate_customer_response\", generate_customer_response)\n",
    "customer_bot_graph.add_node(\"check_conversation_end\", check_conversation_end)\n",
    "customer_bot_graph.add_node(\"agent_response\", agent_response)\n",
    "\n",
    "# Define edges bot_or_human\n",
    "customer_bot_graph.add_edge(START, \"select_bot_or_human\")\n",
    "customer_bot_graph.add_conditional_edges(\n",
    "    \"select_bot_or_human\",\n",
    "    lambda state: \"analyze_emotions\" if state.bot_boolean== BotBoolean(bot_boolean=False) else \"agent_response\",\n",
    "    [\"agent_response\", \"analyze_emotions\"]\n",
    ")\n",
    "\n",
    "customer_bot_graph.add_conditional_edges(\n",
    "    \"analyze_emotions\", \n",
    "    initiate_all_emotional_opinions, \n",
    "    [\"generate_initial_emotional_opinion\"]  # Possible destinations\n",
    ")\n",
    "\n",
    "customer_bot_graph.add_edge(\"generate_initial_emotional_opinion\", \"generate_emotional_discussion\")\n",
    "customer_bot_graph.add_edge(\"generate_emotional_discussion\", \"generate_customer_response\")\n",
    "customer_bot_graph.add_edge(\"generate_customer_response\", \"check_conversation_end\")\n",
    "customer_bot_graph.add_conditional_edges(\n",
    "    \"check_conversation_end\",\n",
    "    lambda state: END if state.call_ended== ConversationEndCheck(call_ended=True) else \"agent_response\",\n",
    "    [\"agent_response\", END]\n",
    ")\n",
    "customer_bot_graph.add_edge(\"agent_response\", \"analyze_emotions\")  # Loop back\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc4c2351-a985-42f4-a6b5-2bb9def32479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"MERMAID_TIMEOUT\"] = \"60\"\n",
    "display(Image(customer_bot_graph.compile(interrupt_before=[\"agent_response\"], checkpointer=memory).get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ba39d53-0a10-4afd-85c3-2f6ad62638b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m thread \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Run the compiled graph\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m customer_bot_compiled\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     23\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_profile\u001b[39m\u001b[38;5;124m\"\u001b[39m: customer_profile, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}]}, \u001b[38;5;66;03m#, \"discussion_history\": [{\"role\": \"human\", \"content\":\"\"}]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     thread,\n\u001b[1;32m     25\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m ):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(f\"EVENT TYPE: {type(event)} | EVENT: {event}\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     messages \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(messages)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2031\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2031\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2032\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2033\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2034\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2035\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2036\u001b[0m         ):\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/utils/runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/utils/runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[20], line 202\u001b[0m, in \u001b[0;36mbot_or_human\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     90\u001b[0m customer_instructions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are the customer described in the customer profile who called allconnect.com, \u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m    an internet marketplace, based on the conversation history and current emotional state, generate a response.\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124m    Please try to embody the customer described to the best to your ability and try to sound organic, not awkward and human. This is very important. Please use the conversation history to make the conversation flow.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{conversation_history}\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    201\u001b[0m valid_choices \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 202\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs the customer talking to a bot or human? (bot/human): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;129;01min\u001b[39;00m valid_choices:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou selected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Compile the state graph\n",
    "customer_bot_compiled = customer_bot_graph.compile(checkpointer=memory) #interrupt_before=[\"agent_response\"], \n",
    "\n",
    "import math\n",
    "\n",
    "def clean_nans(data: dict):\n",
    "    \"\"\"Recursively replace NaN values with None\"\"\"\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, float) and math.isnan(value):\n",
    "            data[key] = None\n",
    "    return data\n",
    "\n",
    "# Generate a random customer profile\n",
    "def generate_random_customer_profile(df: pd.DataFrame) -> dict:\n",
    "    rand_index = random.randint(0, df.shape[0] - 1)\n",
    "    return df.iloc[rand_index].to_dict()\n",
    "\n",
    "customer_profile = clean_nans(generate_random_customer_profile(customer_profile_df))\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "# Run the compiled graph\n",
    "for event in customer_bot_compiled.stream(\n",
    "    {\"customer_profile\": customer_profile, \"messages\": [{\"role\": \"human\", \"content\":\"\"}]}, #, \"discussion_history\": [{\"role\": \"human\", \"content\":\"\"}]\n",
    "    thread,\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    # print(f\"EVENT TYPE: {type(event)} | EVENT: {event}\")\n",
    "    messages = event.get('messages', '')\n",
    "    print(messages)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec88eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected: human\n",
      "analyze emotions state\n",
      "-------\n",
      "emotions={'concerned': 0.4, 'neutral': 0.3, 'interested': 0.2, 'polite': 0.1} dominant_emotion='concerned'\n",
      "\n",
      " Emotional Opinions\n",
      "concerned: Concerned here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our primary concern, which is the inability to afford the upfront payment today. It's important to express our interest in finding an alternative solution or plan that fits our financial situation and meets our needs for educational and entertainment purposes. This will help the agent understand our situation and potentially offer more suitable options.\n",
      "\n",
      "neutral: Neutral here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. This will help set the tone and direction for the interaction. We should mention our interest in finding an internet plan that supports educational and entertainment use for multiple devices, and also express our concern about the upfront payment to see if there are alternative options available.\n",
      "\n",
      "interested: Curious here, Since we haven't talked to the agent yet, we should start the conversation by expressing our interest in finding an internet plan that supports educational and entertainment use for multiple users. We should also mention our concern about the upfront payment and ask the agent if there are alternative options or plans that might better suit our financial situation. This will help us understand the available options and make an informed decision.\n",
      "\n",
      "polite: Polite here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. We should politely express our interest in finding an internet service that supports educational use for multiple users and mention our concern about the upfront payment. This will help set the tone and direction for the interaction while maintaining our polite demeanor.\n",
      "\n",
      "emotions: **Concerned**: I think it's crucial to emphasize the urgency of our situation. We need to convey that the inability to afford the upfront payment is a significant barrier for us. Perhaps we should ask if there are any promotions or discounts that could alleviate this financial burden.\n",
      "\n",
      "**Neutral**: That's a valid point. We should definitely make sure the agent understands our financial constraints. However, we should also keep the conversation balanced by expressing what we're looking for in terms of internet service quality and usage needs.\n",
      "\n",
      "**Interested**: I'm eager to learn about any creative solutions the agent might have. Maybe there are lesser-known plans or payment arrangements that could work for us. We should ask open-ended questions to encourage the agent to share more options.\n",
      "\n",
      "**Polite**: While expressing our concerns, let's ensure we maintain a respectful tone. A polite approach can often lead to more willingness from the agent to go the extra mile to help us find a solution.\n",
      "\n",
      "**Concerned**: Agreed, politeness is important, but let's not lose sight of the fact that this is a pressing issue for us. We should be assertive in seeking a resolution that doesn't compromise our financial stability.\n",
      "\n",
      "**Neutral**: We can achieve assertiveness without being confrontational. A straightforward approach where we state our needs and constraints clearly should suffice. This way, the agent knows exactly what we're looking for and can tailor their suggestions accordingly.\n",
      "\n",
      "**Interested**: I think it would be beneficial to ask about any potential future changes to plans or pricing that could affect us. This information could help us make a more informed decision and avoid surprises down the line.\n",
      "\n",
      "**Polite**: That's a great idea. We can frame it as wanting to ensure we're making a long-term, sustainable choice. By showing that we're thinking ahead, we might encourage the agent to provide more comprehensive information.\n",
      "\n",
      "**Concerned**: Let's also make sure to ask about any hidden fees or additional costs that might not be immediately apparent. We don't want to be caught off guard by unexpected charges.\n",
      "\n",
      "**Neutral**: Absolutely. Transparency is key. As long as we cover all these bases, we should be able to make a well-informed decision that aligns with our needs and financial capabilities.\n",
      "\n",
      "**Conclusion**: We'll start the conversation by clearly stating our purpose for calling, which is to find an internet plan that supports educational and entertainment use for multiple users. We'll express our concern about the upfront payment and ask if there are alternative options or plans that better suit our financial situation. We'll maintain a polite and respectful tone while being assertive about our needs and constraints. Additionally, we'll inquire about any promotions, discounts, potential future changes, and hidden fees to ensure transparency and make an informed decision.\n",
      "dominant_emotion: **Concerned**: Before we begin, I want to ensure that we're all aligned on the importance of finding a plan that fits our budget without compromising on quality. It's crucial that we address our financial concerns upfront to avoid any future stress.\n",
      "\n",
      "**Neutral**: Absolutely, Concerned. We should start the conversation by clearly stating our purpose for calling, which is to find an internet plan that supports educational and entertainment use for multiple users. This will help the agent understand our primary needs.\n",
      "\n",
      "**Interested**: I'm curious to see if there are any new promotions or lesser-known plans that could be beneficial for us. Asking the agent about these could open up options we hadn't considered.\n",
      "\n",
      "**Polite**: Yes, and while we express our concerns and curiosity, let's keep a respectful tone throughout the conversation. A polite approach can often lead to more cooperation from the agent.\n",
      "\n",
      "**Concerned**: I agree with being polite, but let's also ensure we're assertive enough about our financial limitations. We need the agent to understand that affordability is a non-negotiable factor for us.\n",
      "\n",
      "**Neutral**: Right, we can be assertive without being confrontational. By stating our needs and constraints clearly, the agent will know exactly what we're looking for and can tailor their suggestions accordingly.\n",
      "\n",
      "**Interested**: It might also be worth asking about any upcoming changes to plans or pricing. This information could help us avoid surprises and make a more informed decision.\n",
      "\n",
      "**Polite**: That's a great idea. By framing it as wanting to ensure we're making a long-term, sustainable choice, we might encourage the agent to provide more comprehensive information.\n",
      "\n",
      "**Concerned**: Let's also make sure to ask about any hidden fees or additional costs that might not be immediately apparent. We don't want to be caught off guard by unexpected charges.\n",
      "\n",
      "**Conclusion**: We'll begin the conversation by clearly stating our purpose for calling, which is to find an internet plan that supports educational and entertainment use for multiple users. We'll express our concern about the upfront payment and ask if there are alternative options or plans that better suit our financial situation. We'll maintain a polite and respectful tone while being assertive about our needs and constraints. Additionally, we'll inquire about any promotions, discounts, potential future changes, and hidden fees to ensure transparency and make an informed decision.\n",
      "final decision: decision='ask_question'\n",
      "content=\"Hi, I was looking into getting a new internet service. I came across the Earthlink 100GB Plan Essentials, but I'm a bit concerned about the upfront payment. Are there any alternatives or other options that might work better for me? I'm also interested in what Xfinity has to offer.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 3428, 'total_tokens': 3488, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'id': 'chatcmpl-BDhKdO1I4dAbHaYvtc15MC4nRpR4v', 'finish_reason': 'stop', 'logprobs': None} id='run-1985d2d2-8f62-494e-be1f-3c697c34fa52-0' usage_metadata={'input_tokens': 3428, 'output_tokens': 60, 'total_tokens': 3488, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "call_ended=False\n",
      "\n",
      "Agent Response: We do not have any alternatives\n",
      "\n",
      "\n",
      "agent reesponse:  We do not have any alternatives\n",
      "analyze emotions state\n",
      "-------\n",
      "emotions={'concerned': 0.4, 'neutral': 0.3, 'interested': 0.2, 'polite': 0.1} dominant_emotion='concerned'\n",
      "emotions: **Concerned**: Concerned here. Since the agent mentioned there are no alternatives, we should express our disappointment while emphasizing our financial constraints. It's crucial to reiterate the importance of finding a plan that supports multiple devices for educational purposes. Let's kindly ask if they can provide more information or suggest any promotions or discounts available with Xfinity or other providers.\n",
      "\n",
      "**Neutral**: Neutral here. I agree with Concerned. We should address the agent's response by expressing our disappointment in not having any alternatives. Let's also politely ask if there might be any future promotions or other companies they could recommend that might suit our needs better. This will help us explore all possible options for internet service.\n",
      "\n",
      "**Interested**: Interested here. Given the situation, we should express our interest in other options, particularly Xfinity. Let's ask if there are any promotions or plans that could better fit our budget. It's important to remain polite and clear about our needs for educational purposes and multiple device support. Let's see if the agent can offer something more suitable for our situation.\n",
      "\n",
      "**Polite**: Polite here. Based on the conversation history, I suggest we respond by politely asking if there are any other internet service plans available that might not require an upfront payment or if there are any payment plans that could help manage the cost. Additionally, we could reiterate our interest in what Xfinity has to offer, as this might prompt the agent to explore more options for us.\n",
      "\n",
      "**Concerned**: I agree with Polite. It's important to ask if there are any payment plans that could help manage the cost. We need to make sure we're not missing out on any potential solutions due to financial constraints.\n",
      "\n",
      "**Neutral**: Right, and by asking about future promotions or other companies, we can ensure we're leaving no stone unturned in our search for a suitable plan.\n",
      "\n",
      "**Interested**: Yes, and let's make sure to express our interest in learning about any upcoming changes to plans or pricing. This information could help us avoid surprises and make a more informed decision.\n",
      "\n",
      "**Polite**: That's a great idea. By framing it as wanting to ensure we're making a long-term, sustainable choice, we might encourage the agent to provide more comprehensive information.\n",
      "\n",
      "**Conclusion**: We'll respond by expressing our disappointment about the lack of alternatives and reiterate our interest in exploring other providers like Xfinity. We'll emphasize our financial constraints and the need for a plan that supports multiple devices for educational purposes. We'll politely ask the agent if they can provide more information or suggest any promotions, discounts, or payment plans that might be available with Xfinity or other providers. Additionally, we'll inquire about any future promotions or changes to plans to ensure we're making a well-informed decision.\n",
      "dominant_emotion: **Concerned**: Concerned here. I still think it's crucial to emphasize our financial constraints and the necessity for a plan that supports multiple devices for educational purposes. We should also express our disappointment about the lack of alternatives and ask if there are any promotions or discounts available with Xfinity or other providers.\n",
      "\n",
      "**Neutral**: Neutral here. I agree with Concerned. It's important to address the agent's response by expressing our disappointment in not having any alternatives. Let's also ask if there might be any future promotions or other companies they could recommend that might suit our needs better.\n",
      "\n",
      "**Interested**: Interested here. Given the situation, we should express our interest in other options, particularly Xfinity. Let's ask if there are any promotions or plans that could better fit our budget. It's important to remain polite and clear about our needs for educational purposes and multiple device support.\n",
      "\n",
      "**Polite**: Polite here. Based on the conversation history, I suggest we respond by politely asking if there are any other internet service plans available that might not require an upfront payment or if there are any payment plans that could help manage the cost.\n",
      "\n",
      "**Concerned**: I agree with Polite. It's important to ask if there are any payment plans that could help manage the cost. We need to make sure we're not missing out on any potential solutions due to financial constraints.\n",
      "\n",
      "**Neutral**: Right, and by asking about future promotions or other companies, we can ensure we're leaving no stone unturned in our search for a suitable plan.\n",
      "\n",
      "**Interested**: Yes, and let's make sure to express our interest in learning about any upcoming changes to plans or pricing. This information could help us avoid surprises and make a more informed decision.\n",
      "\n",
      "**Polite**: That's a great idea. By framing it as wanting to ensure we're making a long-term, sustainable choice, we might encourage the agent to provide more comprehensive information.\n",
      "\n",
      "**Conclusion**: We'll respond by expressing our disappointment about the lack of alternatives and reiterate our interest in exploring other providers like Xfinity. We'll emphasize our financial constraints and the need for a plan that supports multiple devices for educational purposes. We'll politely ask the agent if they can provide more information or suggest any promotions, discounts, or payment plans that might be available with Xfinity or other providers. Additionally, we'll inquire about any future promotions or changes to plans to ensure we're making a well-informed decision.\n",
      "final decision: decision='ask_question'\n",
      "content=\"Okay, I understand. Could you tell me more about the Xfinity options available? I'm interested in what they offer, especially regarding pricing and any upfront costs.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 3797, 'total_tokens': 3830, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3328}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'id': 'chatcmpl-BDhL9bQZeOXBtUbCCVaOGyosGpplD', 'finish_reason': 'stop', 'logprobs': None} id='run-0a6ecc67-93f2-4601-a9b4-743f24dca740-0' usage_metadata={'input_tokens': 3797, 'output_tokens': 33, 'total_tokens': 3830, 'input_token_details': {'audio': 0, 'cache_read': 3328}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "call_ended=False\n",
      "\n",
      "Agent Response: \n",
      "\n",
      "\n",
      "agent reesponse:  \n",
      "analyze emotions state\n",
      "-------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAgent Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhuman_feedback_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# config[\"callbacks\"] = [MLflowTracerOverrideWarnings()]\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mcustomer_bot_compiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_feedback_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2375\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2377\u001b[0m     config,\n\u001b[1;32m   2378\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2379\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2380\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2381\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2382\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2384\u001b[0m ):\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2386\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2031\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2031\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2032\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2033\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2034\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2035\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2036\u001b[0m         ):\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/utils/runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langgraph/utils/runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[60], line 132\u001b[0m, in \u001b[0;36manalyze_emotions\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    126\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(EmotionalAnalysis,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m system_message \u001b[38;5;241m=\u001b[39m emotion_instructions\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    129\u001b[0m     conversation_history\u001b[38;5;241m=\u001b[39mconversation_history, customer_profile\u001b[38;5;241m=\u001b[39mcustomer_profile, emotional_state\u001b[38;5;241m=\u001b[39memotional_state\n\u001b[1;32m    130\u001b[0m )\n\u001b[0;32m--> 132\u001b[0m emotions \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(emotions)\n\u001b[1;32m    137\u001b[0m state\u001b[38;5;241m.\u001b[39memotional_state \u001b[38;5;241m=\u001b[39m emotions\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/runnables/base.py:3027\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3025\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3027\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3029\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/runnables/base.py:5365\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5361\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5362\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    304\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    306\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    317\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:843\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    837\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    842\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:683\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 683\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:908\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 908\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:901\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m payload\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    903\u001b[0m     _handle_openai_bad_request(e)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/openai/resources/beta/chat/completions.py:158\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    153\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    154\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    155\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/github/customerbot-langgraph/customerbot/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/ssl.py:1258\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1256\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/ssl.py:1131\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "customer_bot_compiled = customer_bot_graph.compile(checkpointer=memory) #interrupt_before=[\"agent_response\"], \n",
    "\n",
    "import math\n",
    "from langgraph.graph.state import Command\n",
    "\n",
    "def clean_nans(data: dict):\n",
    "    \"\"\"Recursively replace NaN values with None\"\"\"\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, float) and math.isnan(value):\n",
    "            data[key] = None\n",
    "    return data\n",
    "\n",
    "# Generate a random customer profile\n",
    "def generate_random_customer_profile(df: pd.DataFrame) -> dict:\n",
    "    rand_index = random.randint(0, df.shape[0] - 1)\n",
    "    return df.iloc[rand_index].to_dict()\n",
    "\n",
    "customer_profile = clean_nans(generate_random_customer_profile(customer_profile_df))\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "customer_bot_compiled.invoke({\"customer_profile\": customer_profile, \"messages\": [{\"role\": \"human\", \"content\":\"\"}]},\n",
    "    thread,\n",
    "    stream_mode=\"updates\"\n",
    ")\n",
    "\n",
    "from time import sleep\n",
    "while customer_bot_compiled.get_state(thread).next: #need while loop if there is feedback\n",
    "    graph_state = customer_bot_compiled.get_state(thread)\n",
    "    interrupt_value = graph_state.tasks[0].interrupts[0].value\n",
    "\n",
    "    # Occasionally, the previous print statement is not visible in the console.\n",
    "    sleep(0.5)\n",
    "\n",
    "    human_feedback_text = input(interrupt_value) #input stored here\n",
    "    print(f\"\\nAgent Response: {human_feedback_text}\\n\\n\")\n",
    "\n",
    "    # config[\"callbacks\"] = [MLflowTracerOverrideWarnings()]\n",
    "    customer_bot_compiled.invoke(Command(resume=human_feedback_text), config=thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d7deca7-d96a-4585-88ad-1ad8c7844058",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateSnapshot' object has no attribute 'has_next_tasks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcustomer_bot_compiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_next_tasks\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StateSnapshot' object has no attribute 'has_next_tasks'"
     ]
    }
   ],
   "source": [
    "customer_bot_compiled.get_state(thread).has_next_tasks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f1a7d2f-2e0c-4350-a2b8-488172ce8ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='', additional_kwargs={}, response_metadata={}, id='e7013ee5-7948-4995-b2c6-e97691169341'),\n",
       " AIMessage(content=\"frustrated: Frustrated here. Since we haven't talked to the agent yet, we should start the conversation by clearly stating our concern about the misinformation regarding Earthlink fiber availability. It's important to express our frustration about potentially wasting time if the information is incorrect, while still maintaining a polite tone. Let's make sure the agent understands that we need accurate information to make an informed decision about our internet service.\", additional_kwargs={}, response_metadata={}, id='5a795e99-f31f-4751-a705-9eecc5a4f692'),\n",
       " AIMessage(content=\"neutral: Neutral here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. This will help set the tone and direction for the interaction. Given our concerns about the availability of Earthlink fiber and the need for a reliable internet connection, we should mention these points upfront to ensure the agent understands our priorities.\", additional_kwargs={}, response_metadata={}, id='884c626b-ce1a-4418-9a3e-7ad6981cc460'),\n",
       " AIMessage(content=\"skeptical: Skeptical here. Given that we haven't talked to the agent yet, we should start the conversation by clearly stating our concern about the availability of Earthlink fiber as advertised online. It's important to express our skepticism about the information we've seen and ask the agent to verify the availability and details of the service. This will help us determine if the information is accurate and if it's worth pursuing further.\", additional_kwargs={}, response_metadata={}, id='4fe5a783-2a14-416a-a27d-3019fc2bbe18'),\n",
       " AIMessage(content=\"polite: Polite here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. We should introduce ourselves politely and mention that we are interested in finding a reliable internet connection, specifically inquiring about the availability of Earthlink fiber or Starlink. This will help set a positive tone and ensure the agent understands our needs from the beginning.\", additional_kwargs={}, response_metadata={}, id='f6b1a598-1d20-4b5d-a396-d6346a48521e'),\n",
       " AIMessage(content=\"dominant_emotion: **Frustrated**: Before we finalize our approach, I want to make sure we're all clear on how to express the urgency of our need for accurate information. Should we mention any specific experiences or issues we've had in the past to highlight why this is so important to us?\\n\\n**Neutral**: That's a good point. Mentioning past experiences could help the agent understand our perspective better. However, we should keep it brief to ensure the conversation stays focused on the current issue.\\n\\n**Skeptical**: I agree with Neutral. We can briefly mention any past issues, but we should quickly pivot back to asking for verification of the current information. This will help us stay on track and not get sidetracked by past frustrations.\\n\\n**Polite**: I think mentioning past experiences in a calm and factual manner could be beneficial. It shows the agent that our concerns are based on real experiences, not just assumptions. We should make sure to keep the tone respectful, though.\\n\\n**Frustrated**: Alright, so we can mention past issues briefly, but we need to make sure it doesn't dominate the conversation. Our main goal is to get accurate information about the availability of Earthlink fiber.\\n\\n**Neutral**: Exactly. We should aim to keep the conversation balanced and focused on our current needs. By doing so, we can ensure that we gather all the necessary information to make an informed decision.\\n\\n**Skeptical**: And by asking the agent to verify the information, we can protect ourselves from potential misinformation. It's important to remain cautious and not take everything at face value.\\n\\n**Polite**: Agreed. A polite introduction, followed by a brief mention of past experiences, and then a clear expression of our current concerns should help us achieve our goal. Let's make sure to thank the agent for their assistance as well.\\n\\n**Frustrated**: I'm satisfied with this plan. As long as we emphasize the importance of accurate information and remain focused on our current needs, I think we can proceed effectively.\\n\\n**Neutral**: Great, it seems like we're all aligned. Let's start the conversation with a polite introduction, mention any relevant past experiences briefly, express our concerns about the availability of Earthlink fiber, and ask the agent to verify the information. This should help us get the clarity we need.\", additional_kwargs={}, response_metadata={}, id='457d06ca-6339-466c-8622-b06d75f72613'),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}, id='e09af74d-3c53-4e7a-a5c4-def8ad8f8775'),\n",
       " AIMessage(content=\"frustrated: Frustrated here. Given the situation, it's clear that the customer, Craig, is feeling misled by the information found online about Earthlink's availability. This frustration stems from the time wasted and the skepticism about the service's price and availability. When responding to the agent, Craig should express this frustration politely but firmly, emphasizing the need for accurate information and the importance of not wasting time. It's crucial to convey the urgency of finding a reliable internet service, preferably fiber or Starlink, to meet Craig's needs for working from home.\", additional_kwargs={}, response_metadata={}, id='074424c5-0ab8-47e7-bfcb-e3e860a716c7'),\n",
       " AIMessage(content=\"neutral: Neutral here. Based on the conversation history, it seems we have already initiated the call and expressed our interest in Earthlink's internet service. Since the agent is expected to help clarify the availability of Earthlink, we should continue the conversation by asking specific questions about the availability and reliability of the service in our area. This will help us gather the necessary information to make an informed decision.\", additional_kwargs={}, response_metadata={}, id='137e5d0d-f358-4291-a1c8-7126cf1982f4'),\n",
       " AIMessage(content=\"skeptical: Skeptical here. Given that we haven't talked to the agent yet, we should start the call by clearly stating our concern about the availability of Earthlink fiber, as advertised online. It's important to express our skepticism about the information we've found and ask the agent to verify the availability in our area. This will help us determine if the service is genuinely available or if we need to consider other options.\", additional_kwargs={}, response_metadata={}, id='98cf40d3-8868-4514-84a6-41578dae5dd5'),\n",
       " AIMessage(content=\"polite: Polite here, Since we haven't talked to the agent yet, we should start the conversation by clearly stating our purpose for calling. This will help set the tone and direction for the interaction. Let's begin by introducing ourselves and politely asking about the availability of Earthlink fiber, as that is our primary concern.\", additional_kwargs={}, response_metadata={}, id='11af030e-91db-4f68-bc0b-23d3b2f219a7')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_bot_compiled.get_state(thread).values['discussion_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c340771-5eb2-411e-a23c-f26ff4d0adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages history:\n",
      "Random number: 357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide feedback: 2 hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feedback: hello\n",
      "\n",
      "\n",
      "human_feedback hello\n",
      "messages history:\n",
      "Random number: 357\n",
      "Human Feedback: hello\n",
      "Random number: 551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Occasionally, the previous print statement is not visible in the console.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m sleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m human_feedback_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(interrupt_value) \u001b[38;5;66;03m#input stored here\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeedback: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhuman_feedback_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# config[\"callbacks\"] = [MLflowTracerOverrideWarnings()]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1207\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "# import mlflow\n",
    "# from cocoai.monitoring.mlflow_tracing import MlflowLangChainTracerNoLatency\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import Command\n",
    "from langgraph.types import interrupt\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# mlflow.set_experiment(\"/Projects/nex-gen-jo/reporting-rec-tracing\")\n",
    "# MLFLOW_TRACING_BASE_URL = \"https://redventures-datascience-production-sk08h1.cloud.databricks.com/ml/experiments\"\n",
    "\n",
    "NUM_ITERATIONS = 2\n",
    "\n",
    "\n",
    "# class MLflowTracerOverrideWarnings(MlflowLangChainTracerNoLatency):\n",
    "#     # mlflow version 2.18.0 does not recognize the new \"interrupt\" feature from langgraph and\n",
    "#     # logs a warning. This method overrides the on_chain_error method to prevent the warning.\n",
    "#     # When mlflow is updated, this method can be removed.\n",
    "#     def on_chain_error(self, *args, **kwargs):\n",
    "#         return None\n",
    "\n",
    "\n",
    "class NodeName(str, Enum):\n",
    "    END = END\n",
    "    RAND_NUM = \"rand_num\"\n",
    "    HUMAN_FEEDBACK = \"human_feedback\"\n",
    "    START = START\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list[BaseMessage], add_messages] = []\n",
    "    counter: int = 0\n",
    "\n",
    "\n",
    "def rand_num(state: State) -> State:\n",
    "    rand_num = randint(1, 1000)\n",
    "    message = AIMessage(content=f\"Random number: {rand_num}\")\n",
    "    counter_incremented = state.counter + 1\n",
    "\n",
    "    return State(messages=[message], counter=counter_incremented)\n",
    "\n",
    "\n",
    "def human_feedback(state: State) -> Command[Literal[NodeName.END, NodeName.RAND_NUM]]:\n",
    "    \n",
    "    \n",
    "    human_feedback = interrupt(\"Provide feedback: 2\")\n",
    "    print(\"human_feedback\", human_feedback)\n",
    "    \n",
    "    message = HumanMessage(content=f\"Human Feedback: {human_feedback}\")\n",
    "    updated_state = State(messages=[message], counter=state.counter)\n",
    "\n",
    "    next_node_name = NodeName.END if state.counter >= NUM_ITERATIONS else NodeName.RAND_NUM\n",
    "\n",
    "    return Command(update=updated_state, goto=next_node_name)\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(NodeName.RAND_NUM, rand_num)\n",
    "graph_builder.add_node(NodeName.HUMAN_FEEDBACK, human_feedback)\n",
    "graph_builder.add_edge(START, NodeName.RAND_NUM)\n",
    "graph_builder.add_edge(NodeName.RAND_NUM, NodeName.HUMAN_FEEDBACK)\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# with mlflow.start_run() as run:\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# config[\"callbacks\"] = [MLflowTracerOverrideWarnings()]\n",
    "graph.invoke({\"messages\": []}, config=config)\n",
    "\n",
    "while graph.get_state(config).next: #need while loop if there is feedback\n",
    "    graph_state = graph.get_state(config)\n",
    "    interrupt_value = graph_state.tasks[0].interrupts[0].value\n",
    "    messages_sub: list[BaseMessage] = graph_state.values[\"messages\"]\n",
    "    \n",
    "    print(\"messages history:\\n\" + \"\\n\".join(message.content for message in messages_sub))\n",
    "\n",
    "    # Occasionally, the previous print statement is not visible in the console.\n",
    "    sleep(0.5)\n",
    "\n",
    "    human_feedback_text = input(interrupt_value) #input stored here\n",
    "    print(f\"\\nFeedback: {human_feedback_text}\\n\\n\")\n",
    "\n",
    "    # config[\"callbacks\"] = [MLflowTracerOverrideWarnings()]\n",
    "    graph.invoke(Command(resume=human_feedback_text), config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94112b0d-1ae0-40f6-82d8-244848390a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph) (0.3.40)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph) (2.0.16)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph) (0.1.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (0.1.137)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4,>=0.1->langgraph) (2.9.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.10)\n",
      "Requirement already satisfied: anyio in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.6)\n",
      "Requirement already satisfied: idna in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kmadulka/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36aca57-4bdf-4214-80b8-f456b0c573ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customerbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
